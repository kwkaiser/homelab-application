NAME: bingus
LAST DEPLOYED: Mon Nov  6 18:02:23 2023
NAMESPACE: default
STATUS: pending-upgrade
REVISION: 5
TEST SUITE: None
HOOKS:
MANIFEST:
---
# Source: homelab/charts/reloader/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    meta.helm.sh/release-namespace: "default"
    meta.helm.sh/release-name: "bingus"
  labels:
    app: bingus-reloader
    chart: "reloader-1.0.50"
    release: "bingus"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
  name: bingus-reloader
  namespace: default
---
# Source: homelab/templates/authelia/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: authelia-configs
data:
  configuration.yaml: "---\ntheme: dark\njwt_secret: a_very_important_secret\ndefault_redirection_url: http://google.com\ndefault_2fa_method: \"\"\n\nserver:\n  host: 0.0.0.0\n  port: 9091\n  path: \"\"\n  disable_healthcheck: false\n\ntelemetry:\n  metrics:\n    enabled: true\n    address: \"tcp://0.0.0.0:9959\"\n    buffers:\n      read: 4096\n      write: 4096\n    timeouts:\n      read: 6s\n      write: 6s\n      idle: 30s\n\nlog:\n  level: trace\n  format: json\n\nauthentication_backend:\n  password_reset:\n    disable: false\n  refresh_interval: 1m\n\n  ldap:\n    implementation: custom\n    url: ldap://openldap\n    timeout: 30s\n    start_tls: false\n    base_dn: dc=kwkaiser-test,dc=io\n    additional_users_dn: ou=people\n    users_filter: ({username_attribute}={input})\n    username_attribute: uid\n    mail_attribute: mail\n    display_name_attribute: displayName\n    additional_groups_dn: ou=groups\n    groups_filter: (&(member={dn})(|(sAMAccountType=268435456)(sAMAccountType=536870912)))\n    group_name_attribute: cn\n    permit_referrals: false\n    permit_unauthenticated_bind: false\n    user: CN=admin,DC=kwkaiser-test,DC=io\n\npassword_policy:\n  standard:\n    enabled: false\n    min_length: 8\n    max_length: 0\n    require_uppercase: true\n    require_lowercase: true\n    require_number: true\n    require_special: true\n  zxcvbn:\n    enabled: false\n    min_score: 3\n\naccess_control:\n  default_policy: deny\n  rules:\n    - domain_regex: '(scurvy|movies|tv|trackers|ratio|games|books|metrics).kwkaiser-test.io'\n      policy: one_factor\n      subject:\n        - [\"user:kwkaiser\"] \n\nstorage:\n  local:\n    path: /config/db.sqlite3\n\nsession:\n  domain: kwkaiser-test.io\n  name: authelia_session\n  same_site: lax\n  inactivity: 5m\n  expiration: 1h\n\nregulation:\n  max_retries: 3\n  find_time: 2m\n  ban_time: 5m\n\nnotifier:\n  disable_startup_check: true\n  filesystem:\n    filename: /config/notification.txt\n"
---
# Source: homelab/templates/gitea/renovate/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: renovate-configs
data:
  config.json: "{\n  \"$schema\": \"https://docs.renovatebot.com/renovate-schema.json\",\n  \"extends\": [\"config:base\"],\n  \"platform\": \"gitea\",\n  \"endpoint\": \"http://gitea\",\n  \"gitAuthor\": \"Renovate Bot <bot@renovateapp.com>\",\n  \"customManagers\": [\n    {\n      \"customType\": \"regex\",\n      \"fileMatch\": [\"values\\\\.yaml\"],\n      \"matchStrings\": [\"(image_.*): \\\"(?<depName>.+):(?<currentValue>.+)\\\"\"],\n      \"datasourceTemplate\": \"docker\"\n    }\n  ]\n}\n"
---
# Source: homelab/templates/nginx/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-configs
data:
  
  authelia-endpoint.conf: "## Send a subrequest to Authelia to verify if the user is authenticated and has permission to access the resource.\nauth_request /authelia;\n\n## Set the $target_url variable based on the original request.\n\n## Comment this line if you're using nginx without the http_set_misc module.\n# set_escape_uri $target_url $scheme://$http_host$request_uri;\n## Uncomment this line if you're using NGINX without the http_set_misc module.\nset $target_url https://$http_host$request_uri;\n## Save the upstream response headers from Authelia to variables.\nauth_request_set $user $upstream_http_remote_user;\nauth_request_set $groups $upstream_http_remote_groups;\nauth_request_set $name $upstream_http_remote_name;\nauth_request_set $email $upstream_http_remote_email;\n\n## Inject the response headers from the variables into the request made to the backend.\nproxy_set_header Remote-User $user;\nproxy_set_header Remote-Groups $groups;\nproxy_set_header Remote-Name $name;\nproxy_set_header Remote-Email $email;\n\n## If the subreqest returns 200 pass to the backend, if the subrequest returns 401 redirect to the portal.\nerror_page 401 =302 https://auth.kwkaiser-test.io/?rd=$target_url;"
  
  authelia-location.conf: "set $upstream_authelia http://authelia/api/verify;\n\n## Virtual endpoint created by nginx to forward auth requests.\nlocation /authelia {\n  ## Essential Proxy Configuration\n  internal;\n  proxy_pass $upstream_authelia;\n\n  ## Headers\n  ## The headers starting with X-* are required.\n  proxy_set_header X-Original-URL $scheme://$http_host$request_uri;\n  proxy_set_header X-Original-Method $request_method;\n  proxy_set_header X-Forwarded-Method $request_method;\n  proxy_set_header X-Forwarded-Proto $scheme;\n  proxy_set_header X-Forwarded-Host $http_host;\n  proxy_set_header X-Forwarded-Uri $request_uri;\n  proxy_set_header X-Forwarded-For $remote_addr;\n  proxy_set_header Content-Length \"\";\n  proxy_set_header Connection \"\";\n\n  ## Basic Proxy Configuration\n  proxy_pass_request_body off;\n  proxy_next_upstream error timeout invalid_header http_500 http_502 http_503; # Timeout if the real server is dead\n  proxy_redirect http:// $scheme://;\n  proxy_http_version 1.1;\n  proxy_cache_bypass $cookie_session;\n  proxy_no_cache $cookie_session;\n  proxy_buffers 4 32k;\n  client_body_buffer_size 128k;\n\n  ## Advanced Proxy Configuration\n  send_timeout 5m;\n  proxy_read_timeout 240;\n  proxy_send_timeout 240;\n  proxy_connect_timeout 240;\n}"
  
  authelia-proxy.conf: "## Headers\nproxy_set_header Host $host;\nproxy_set_header X-Original-URL $scheme://$http_host$request_uri;\nproxy_set_header X-Forwarded-Proto $scheme;\nproxy_set_header X-Forwarded-Host $http_host;\nproxy_set_header X-Forwarded-Uri $request_uri;\nproxy_set_header X-Forwarded-Ssl on;\nproxy_set_header X-Forwarded-For $remote_addr;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header Connection \"\";\n\n## Basic Proxy Configuration\nclient_body_buffer_size 128k;\nproxy_next_upstream error timeout invalid_header http_500 http_502 http_503; ## Timeout if the real server is dead.\nproxy_redirect http:// $scheme://;\nproxy_http_version 1.1;\nproxy_cache_bypass $cookie_session;\nproxy_no_cache $cookie_session;\nproxy_buffers 64 256k;\n\n## Trusted Proxies Configuration\n## Please read the following documentation before configuring this:\n##     https://www.authelia.com/integration/proxies/nginx/#trusted-proxies\n# set_real_ip_from 10.0.0.0/8;\n# set_real_ip_from 172.16.0.0/12;\n# set_real_ip_from 192.168.0.0/16;\n# set_real_ip_from fc00::/7;\nreal_ip_header X-Forwarded-For;\nreal_ip_recursive on;\n\n## Advanced Proxy Configuration\nsend_timeout 5m;\nproxy_read_timeout 360;\nproxy_send_timeout 360;\nproxy_connect_timeout 360;"
  
  conf.d_auth.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name auth.*;\n\n  location / {\n    include authelia-proxy.conf;\n    proxy_pass http://authelia;\n  }\n\n  location /api/verify {\n    proxy_pass http://authelia;\n  }\n}\n\n"
  
  conf.d_books.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name books.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  include authelia-location.conf;\n\n  location / {\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $http_connection;\n\n    include authelia-proxy.conf;\n    include authelia-endpoint.conf;\n\n    proxy_pass http://calibre;\n  }\n}\n"
  
  conf.d_default.conf: "server {\n  listen 80 default_server;\n  server_name _;\n  return 301 https://$host$request_uri;\n}\n\nserver {\n  listen 443 ssl default_server;\n  include https.conf;\n\n  server_name _;\n\n  location / {\n    root /usr/share/nginx/html; #Change this line\n    index index.html index.htm;\n  }\n}"
  
  conf.d_git.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name git.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  location / {\n    proxy_pass http://gitea;\n  }\n}\n"
  
  conf.d_ldap-user-manager.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name users.*;\n\n  location / {\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $host;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    add_header X-Frame-Options \"\";\n    proxy_set_header X-Scheme $scheme;\n\n    proxy_pass http://ldap-user-manager;\n  }\n}"
  
  conf.d_movies.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name movies.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  include authelia-location.conf;\n\n  location / {\n    include authelia-proxy.conf;\n    include authelia-endpoint.conf;\n\n    proxy_pass http://radarr;\n  }\n}\n"
  
  conf.d_news.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name news.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  location / {\n    proxy_pass http://miniflux;\n  }\n}\n"
  
  conf.d_ratio.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name ratio.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  include authelia-location.conf;\n\n  proxy_set_header Host $host;\n  proxy_set_header X-Real-IP $remote_addr;\n  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n  proxy_set_header Upgrade $http_upgrade;\n  proxy_set_header Connection $http_connection;\n\n  location / {\n    include authelia-proxy.conf;\n    include authelia-endpoint.conf;\n\n    proxy_pass http://autobrr;\n  }\n}\n"
  
  conf.d_scurvy.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name scurvy.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  include authelia-location.conf;\n\n  location / {\n    include authelia-proxy.conf;\n    include authelia-endpoint.conf;\n\n    proxy_pass http://qbittorrent;\n  }\n}\n"
  
  conf.d_stats.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name stats.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  location / {\n    proxy_set_header Host $http_host;\n    proxy_pass http://grafana;\n  }\n}\n"
  
  conf.d_trackers.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name trackers.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  include authelia-location.conf;\n\n  location / {\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $http_connection;\n\n    include authelia-proxy.conf;\n    include authelia-endpoint.conf;\n\n    proxy_pass http://prowlarr;\n  }\n}\n"
  
  conf.d_tv.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name tv.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  include authelia-location.conf;\n\n  location / {\n    include authelia-proxy.conf;\n    include authelia-endpoint.conf;\n\n    proxy_pass http://sonarr;\n  }\n}\n"
  
  conf.d_watch.conf: "server {\n  listen 443 ssl;\n  include https.conf;\n\n  server_name watch.*;\n\n  fastcgi_buffers 16 16k;\n  fastcgi_buffer_size 32k;\n\n  location / {\n    proxy_pass http://jellyfin;\n  }\n}\n"
  
  https.conf: "ssl_certificate keys/kwkaiser-test.io.crt;\nssl_certificate_key keys/kwkaiser-test.io.key;\n\nssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;\nssl_ciphers HIGH:!aNULL:!MD5;"
  
  nginx.conf: "user nginx;\nworker_processes auto;\n\nevents {\n  worker_connections 10240;\n}\n\nhttp {\n  include /etc/nginx/conf.d/*.conf;\n}"
---
# Source: homelab/templates/observability/grafana/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-configs
data:
  config.ini: "##################### Grafana Configuration Defaults #####################\n#\n# Do not modify this file in grafana installs\n#\n\n# possible values : production, development\napp_mode = production\n\n# instance name, defaults to HOSTNAME environment variable value or hostname if HOSTNAME var is empty\ninstance_name = ${HOSTNAME}\n\n# force migration will run migrations that might cause dataloss\nforce_migration = false\n\n#################################### Paths ###############################\n[paths]\n# Path to where grafana can store temp files, sessions, and the sqlite3 db (if that is used)\ndata = data\n\n# Temporary files in `data` directory older than given duration will be removed\ntemp_data_lifetime = 24h\n\n# Directory where grafana can store logs\nlogs = data/log\n\n# Directory where grafana will automatically scan and look for plugins\nplugins = data/plugins\n\n# folder that contains provisioning config files that grafana will apply on startup and while running.\nprovisioning = conf/provisioning\n\n#################################### Server ##############################\n[server]\n# Protocol (http, https, h2, socket)\nprotocol = http\n\n# Minimum TLS version allowed. By default, this value is empty. Accepted values are: TLS1.2, TLS1.3. If nothing is set TLS1.2 would be taken\nmin_tls_version = \"\"\n\n# The ip address to bind to, empty will bind to all interfaces\nhttp_addr =\n\n# The http port to use\nhttp_port = 3000\n\n# The public facing domain name used to access grafana from a browser\ndomain = localhost\n\n# Redirect to correct domain if host header does not match domain\n# Prevents DNS rebinding attacks\nenforce_domain = false\n\n# The full public facing url\nroot_url = %(protocol)s://%(domain)s:%(http_port)s/\n\n# Serve Grafana from subpath specified in `root_url` setting. By default it is set to `false` for compatibility reasons.\nserve_from_sub_path = false\n\n# Log web requests\nrouter_logging = false\n\n# the path relative working path\nstatic_root_path = public\n\n# enable gzip\nenable_gzip = false\n\n# https certs & key file\ncert_file =\ncert_key =\n\n# Unix socket gid\n# Changing the gid of a file without privileges requires that the target group is in the group of the process and that the process is the file owner\n# It is recommended to set the gid as http server user gid\n# Not set when the value is -1\nsocket_gid = -1\n\n# Unix socket mode\nsocket_mode = 0660\n\n# Unix socket path\nsocket = /tmp/grafana.sock\n\n# CDN Url\ncdn_url =\n\n# Sets the maximum time in minutes before timing out read of an incoming request and closing idle connections.\n# `0` means there is no timeout for reading the request.\nread_timeout = 0\n\n# This setting enables you to specify additional headers that the server adds to HTTP(S) responses.\n[server.custom_response_headers]\n#exampleHeader1 = exampleValue1\n#exampleHeader2 = exampleValue2\n\n#################################### GRPC Server #########################\n[grpc_server]\nnetwork = \"tcp\"\naddress = \"127.0.0.1:10000\"\nuse_tls = false\ncert_file =\nkey_file =\n\n#################################### Database ############################\n[database]\n# You can configure the database connection by specifying type, host, name, user and password\n# as separate properties or as on string using the url property.\n\n# Either \"mysql\", \"postgres\" or \"sqlite3\", it's your choice\ntype = sqlite3\nhost = 127.0.0.1:3306\nname = grafana\nuser = root\n# If the password contains # or ; you have to wrap it with triple quotes. Ex \"\"\"#password;\"\"\"\npassword =\n# Use either URL or the previous fields to configure the database\n# Example: mysql://user:secret@host:port/database\nurl =\n\n# Max idle conn setting default is 2\nmax_idle_conn = 2\n\n# Max conn setting default is 0 (mean not set)\nmax_open_conn =\n\n# Connection Max Lifetime default is 14400 (means 14400 seconds or 4 hours)\nconn_max_lifetime = 14400\n\n# Set to true to log the sql calls and execution times.\nlog_queries =\n\n# For \"postgres\", use either \"disable\", \"require\" or \"verify-full\"\n# For \"mysql\", use either \"true\", \"false\", or \"skip-verify\".\nssl_mode = disable\n\n# Database drivers may support different transaction isolation levels.\n# Currently, only \"mysql\" driver supports isolation levels.\n# If the value is empty - driver's default isolation level is applied.\n# For \"mysql\" use \"READ-UNCOMMITTED\", \"READ-COMMITTED\", \"REPEATABLE-READ\" or \"SERIALIZABLE\".\nisolation_level =\n\nca_cert_path =\nclient_key_path =\nclient_cert_path =\nserver_cert_name =\n\n# For \"sqlite3\" only, path relative to data_path setting\npath = grafana.db\n\n# For \"sqlite3\" only. cache mode setting used for connecting to the database\ncache_mode = private\n\n# For \"sqlite3\" only. Enable/disable Write-Ahead Logging, https://sqlite.org/wal.html. Default is false.\nwal = false\n\n# For \"mysql\" only if migrationLocking feature toggle is set. How many seconds to wait before failing to lock the database for the migrations, default is 0.\nlocking_attempt_timeout_sec = 0\n\n# For \"sqlite\" only. How many times to retry query in case of database is locked failures. Default is 0 (disabled).\nquery_retries = 0\n\n# For \"sqlite\" only. How many times to retry transaction in case of database is locked failures. Default is 5.\ntransaction_retries = 5\n\n# Set to true to add metrics and tracing for database queries.\ninstrument_queries = false\n\n#################################### Cache server #############################\n[remote_cache]\n# Either \"redis\", \"memcached\" or \"database\" default is \"database\"\ntype = database\n\n# cache connectionstring options\n# database: will use Grafana primary database.\n# redis: config like redis server e.g. `addr=127.0.0.1:6379,pool_size=100,db=0,ssl=false`. Only addr is required. ssl may be 'true', 'false', or 'insecure'.\n# memcache: 127.0.0.1:11211\nconnstr =\n\n# prefix prepended to all the keys in the remote cache\nprefix =\n\n# This enables encryption of values stored in the remote cache\nencryption =\n\n#################################### Data proxy ###########################\n[dataproxy]\n\n# This enables data proxy logging, default is false\nlogging = false\n\n# How long the data proxy waits to read the headers of the response before timing out, default is 30 seconds.\n# This setting also applies to core backend HTTP data sources where query requests use an HTTP client with timeout set.\ntimeout = 30\n\n# How long the data proxy waits to establish a TCP connection before timing out, default is 10 seconds.\ndialTimeout = 10\n\n# How many seconds the data proxy waits before sending a keepalive request.\nkeep_alive_seconds = 30\n\n# How many seconds the data proxy waits for a successful TLS Handshake before timing out.\ntls_handshake_timeout_seconds = 10\n\n# How many seconds the data proxy will wait for a server's first response headers after\n# fully writing the request headers if the request has an \"Expect: 100-continue\"\n# header. A value of 0 will result in the body being sent immediately, without\n# waiting for the server to approve.\nexpect_continue_timeout_seconds = 1\n\n# Optionally limits the total number of connections per host, including connections in the dialing,\n# active, and idle states. On limit violation, dials will block.\n# A value of zero (0) means no limit.\nmax_conns_per_host = 0\n\n# The maximum number of idle connections that Grafana will keep alive.\nmax_idle_connections = 100\n\n# How many seconds the data proxy keeps an idle connection open before timing out.\nidle_conn_timeout_seconds = 90\n\n# If enabled and user is not anonymous, data proxy will add X-Grafana-User header with username into the request.\nsend_user_header = false\n\n# Limit the amount of bytes that will be read/accepted from responses of outgoing HTTP requests.\nresponse_limit = 0\n\n# Limits the number of rows that Grafana will process from SQL data sources.\nrow_limit = 1000000\n\n# Sets a custom value for the `User-Agent` header for outgoing data proxy requests. If empty, the default value is `Grafana/<BuildVersion>` (for example `Grafana/9.0.0`).\nuser_agent =\n\n#################################### Analytics ###########################\n[analytics]\n# Server reporting, sends usage counters to stats.grafana.org every 24 hours.\n# No ip addresses are being tracked, only simple counters to track\n# running instances, dashboard and error counts. It is very helpful to us.\n# Change this option to false to disable reporting.\nreporting_enabled = true\n\n# The name of the distributor of the Grafana instance. Ex hosted-grafana, grafana-labs\nreporting_distributor = grafana-labs\n\n# Set to false to disable all checks to https://grafana.com\n# for new versions of grafana. The check is used\n# in some UI views to notify that a grafana update exists.\n# This option does not cause any auto updates, nor send any information\n# only a GET request to https://raw.githubusercontent.com/grafana/grafana/main/latest.json to get the latest version.\ncheck_for_updates = true\n\n# Set to false to disable all checks to https://grafana.com\n# for new versions of plugins. The check is used\n# in some UI views to notify that a plugin update exists.\n# This option does not cause any auto updates, nor send any information\n# only a GET request to https://grafana.com to get the latest versions.\ncheck_for_plugin_updates = true\n\n# Google Analytics universal tracking code, only enabled if you specify an id here\ngoogle_analytics_ua_id =\n\n# Google Analytics 4 tracking code, only enabled if you specify an id here\ngoogle_analytics_4_id =\n\n# When Google Analytics 4 Enhanced event measurement is enabled, we will try to avoid sending duplicate events and let Google Analytics 4 detect navigation changes, etc.\ngoogle_analytics_4_send_manual_page_views = false\n\n# Google Tag Manager ID, only enabled if you specify an id here\ngoogle_tag_manager_id =\n\n# Rudderstack write key, enabled only if rudderstack_data_plane_url is also set\nrudderstack_write_key =\n\n# Rudderstack data plane url, enabled only if rudderstack_write_key is also set\nrudderstack_data_plane_url =\n\n# Rudderstack SDK url, optional, only valid if rudderstack_write_key and rudderstack_data_plane_url is also set\nrudderstack_sdk_url =\n\n# Rudderstack Config url, optional, used by Rudderstack SDK to fetch source config\nrudderstack_config_url =\n\n# Intercom secret, optional, used to hash user_id before passing to Intercom via Rudderstack\nintercom_secret =\n\n# Application Insights connection string. Specify an URL string to enable this feature.\napplication_insights_connection_string =\n\n# Optional. Specifies an Application Insights endpoint URL where the endpoint string is wrapped in backticks ``.\napplication_insights_endpoint_url =\n\n# Controls if the UI contains any links to user feedback forms\nfeedback_links_enabled = true\n\n#################################### Security ############################\n[security]\n# disable creation of admin user on first start of grafana\ndisable_initial_admin_creation = false\n\n# default admin user, created on startup\nadmin_user = kwkaiser\n\n# default admin password, can be changed before first start of grafana, or in profile settings\nadmin_password = admin\n\n# default admin email, created on startup\nadmin_email = admin@localhost\n\n# used for signing\nsecret_key = SW2YcwTIb9zpOOhoPsMm\n\n# current key provider used for envelope encryption, default to static value specified by secret_key\nencryption_provider = secretKey.v1\n\n# list of configured key providers, space separated (Enterprise only): e.g., awskms.v1 azurekv.v1\navailable_encryption_providers =\n\n# disable gravatar profile images\ndisable_gravatar = false\n\n# data source proxy whitelist (ip_or_domain:port separated by spaces)\ndata_source_proxy_whitelist =\n\n# disable protection against brute force login attempts\ndisable_brute_force_login_protection = false\n\n# set to true if you host Grafana behind HTTPS. default is false.\ncookie_secure = false\n\n# set cookie SameSite attribute. defaults to `lax`. can be set to \"lax\", \"strict\", \"none\" and \"disabled\"\ncookie_samesite = lax\n\n# set to true if you want to allow browsers to render Grafana in a <frame>, <iframe>, <embed> or <object>. default is false.\nallow_embedding = false\n\n# Set to true if you want to enable http strict transport security (HSTS) response header.\n# HSTS tells browsers that the site should only be accessed using HTTPS.\nstrict_transport_security = false\n\n# Sets how long a browser should cache HSTS. Only applied if strict_transport_security is enabled.\nstrict_transport_security_max_age_seconds = 86400\n\n# Set to true if to enable HSTS preloading option. Only applied if strict_transport_security is enabled.\nstrict_transport_security_preload = false\n\n# Set to true if to enable the HSTS includeSubDomains option. Only applied if strict_transport_security is enabled.\nstrict_transport_security_subdomains = false\n\n# Set to true to enable the X-Content-Type-Options response header.\n# The X-Content-Type-Options response HTTP header is a marker used by the server to indicate that the MIME types advertised\n# in the Content-Type headers should not be changed and be followed.\nx_content_type_options = true\n\n# Set to true to enable the X-XSS-Protection header, which tells browsers to stop pages from loading\n# when they detect reflected cross-site scripting (XSS) attacks.\nx_xss_protection = true\n\n# Enable adding the Content-Security-Policy header to your requests.\n# CSP allows to control resources the user agent is allowed to load and helps prevent XSS attacks.\ncontent_security_policy = false\n\n# Set Content Security Policy template used when adding the Content-Security-Policy header to your requests.\n# $NONCE in the template includes a random nonce.\n# $ROOT_PATH is server.root_url without the protocol.\ncontent_security_policy_template = \"\"\"script-src 'self' 'unsafe-eval' 'unsafe-inline' 'strict-dynamic' $NONCE;object-src 'none';font-src 'self';style-src 'self' 'unsafe-inline' blob:;img-src * data:;base-uri 'self';connect-src 'self' grafana.com ws://$ROOT_PATH wss://$ROOT_PATH;manifest-src 'self';media-src 'none';form-action 'self';\"\"\"\n\n# Enable adding the Content-Security-Policy-Report-Only header to your requests.\n# Allows you to monitor the effects of a policy without enforcing it.\ncontent_security_policy_report_only = false\n\n# Set Content Security Policy Report Only template used when adding the Content-Security-Policy-Report-Only header to your requests.\n# $NONCE in the template includes a random nonce.\n# $ROOT_PATH is server.root_url without the protocol.\ncontent_security_policy_report_only_template = \"\"\"script-src 'self' 'unsafe-eval' 'unsafe-inline' 'strict-dynamic' $NONCE;object-src 'none';font-src 'self';style-src 'self' 'unsafe-inline' blob:;img-src * data:;base-uri 'self';connect-src 'self' grafana.com ws://$ROOT_PATH wss://$ROOT_PATH;manifest-src 'self';media-src 'none';form-action 'self';\"\"\"\n\n# Controls if old angular plugins are supported or not. This will be disabled by default in future release\nangular_support_enabled = true\n\n# The CSRF check will be executed even if the request has no login cookie.\ncsrf_always_check = false\n\n# Comma-separated list of plugins ids that won't be loaded inside the frontend sandbox\ndisable_frontend_sandbox_for_plugins =\n\n[security.encryption]\n# Defines the time-to-live (TTL) for decrypted data encryption keys stored in memory (cache).\n# Please note that small values may cause performance issues due to a high frequency decryption operations.\ndata_keys_cache_ttl = 15m\n\n# Defines the frequency of data encryption keys cache cleanup interval.\n# On every interval, decrypted data encryption keys that reached the TTL are removed from the cache.\ndata_keys_cache_cleanup_interval = 1m\n\n#################################### Snapshots ###########################\n[snapshots]\n# set to false to remove snapshot functionality\nenabled = true\n\n# snapshot sharing options\nexternal_enabled = true\nexternal_snapshot_url = https://snapshots.raintank.io\nexternal_snapshot_name = Publish to snapshots.raintank.io\n\n# Set to true to enable this Grafana instance act as an external snapshot server and allow unauthenticated requests for\n# creating and deleting snapshots.\npublic_mode = false\n\n# remove expired snapshot\nsnapshot_remove_expired = true\n\n#################################### Dashboards ##################\n\n[dashboards]\n# Number dashboard versions to keep (per dashboard). Default: 20, Minimum: 1\nversions_to_keep = 20\n\n# Minimum dashboard refresh interval. When set, this will restrict users to set the refresh interval of a dashboard lower than given interval. Per default this is 5 seconds.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nmin_refresh_interval = 5s\n\n# Path to the default home dashboard. If this value is empty, then Grafana uses StaticRootPath + \"dashboards/home.json\"\ndefault_home_dashboard_path =\n\n################################### Data sources #########################\n[datasources]\n# Upper limit of data sources that Grafana will return. This limit is a temporary configuration and it will be deprecated when pagination will be introduced on the list data sources API.\ndatasource_limit = 5000\n\n\n################################### SQL Data Sources #####################\n[sql_datasources]\n# Default maximum number of open connections maintained in the connection pool\n# when connecting to SQL based data sources\nmax_open_conns_default = 100\n\n# Default maximum number of idle connections maintained in the connection pool\n# when connecting to SQL based data sources\nmax_idle_conns_default = 100\n\n# Default maximum connection lifetime used when connecting\n# to SQL based data sources.\nmax_conn_lifetime_default = 14400\n\n#################################### Users ###############################\n[users]\n# disable user signup / registration\nallow_sign_up = false\n\n# Allow non admin users to create organizations\nallow_org_create = false\n\n# Set to true to automatically assign new users to the default organization (id 1)\nauto_assign_org = true\n\n# Set this value to automatically add new users to the provided organization (if auto_assign_org above is set to true)\nauto_assign_org_id = 1\n\n# Default role new users will be automatically assigned\nauto_assign_org_role = Viewer\n\n# Require email validation before sign up completes\nverify_email_enabled = false\n\n# Background text for the user field on the login page\nlogin_hint = email or username\npassword_hint = password\n\n# Default UI theme (\"dark\" or \"light\" or \"system\")\ndefault_theme = dark\n\n# Default UI language (supported IETF language tag, such as en-US)\ndefault_language = en-US\n\n# Path to a custom home page. Users are only redirected to this if the default home dashboard is used. It should match a frontend route and contain a leading slash.\nhome_page =\n\n# External user management\nexternal_manage_link_url =\nexternal_manage_link_name =\nexternal_manage_info =\n\n# Viewers can edit/inspect dashboard settings in the browser. But not save the dashboard.\nviewers_can_edit = false\n\n# Editors can administrate dashboard, folders and teams they create\neditors_can_admin = false\n\n# The duration in time a user invitation remains valid before expiring. This setting should be expressed as a duration. Examples: 6h (hours), 2d (days), 1w (week). Default is 24h (24 hours). The minimum supported duration is 15m (15 minutes).\nuser_invite_max_lifetime_duration = 24h\n\n# Enter a comma-separated list of usernames to hide them in the Grafana UI. These users are shown to Grafana admins and to themselves.\nhidden_users =\n\n[secretscan]\n# Enable secretscan feature\nenabled = false\n\n# Interval to check for token leaks\ninterval = 5m\n\n# base URL of the grafana token leak check service\nbase_url = https://secret-scanning.grafana.net\n\n# URL to send outgoing webhooks to in case of detection\noncall_url =\n\n# Whether to revoke the token if a leak is detected or just send a notification\nrevoke = true\n\n[service_accounts]\n# When set, Grafana will not allow the creation of tokens with expiry greater than this setting.\ntoken_expiration_day_limit =\n\n[auth]\n# Login cookie name\nlogin_cookie_name = grafana_session\n\n# Disable usage of Grafana build-in login solution.\ndisable_login = false\n\n# The maximum lifetime (duration) an authenticated user can be inactive before being required to login at next visit. Default is 7 days (7d). This setting should be expressed as a duration, e.g. 5m (minutes), 6h (hours), 10d (days), 2w (weeks), 1M (month). The lifetime resets at each successful token rotation (token_rotation_interval_minutes).\nlogin_maximum_inactive_lifetime_duration =\n\n# The maximum lifetime (duration) an authenticated user can be logged in since login time before being required to login. Default is 30 days (30d). This setting should be expressed as a duration, e.g. 5m (minutes), 6h (hours), 10d (days), 2w (weeks), 1M (month).\nlogin_maximum_lifetime_duration =\n\n# How often should auth tokens be rotated for authenticated users when being active. The default is each 10 minutes.\ntoken_rotation_interval_minutes = 10\n\n# Set to true to disable (hide) the login form, useful if you use OAuth\ndisable_login_form = false\n\n# Set to true to disable the sign out link in the side menu. Useful if you use auth.proxy or auth.jwt.\ndisable_signout_menu = false\n\n# URL to redirect the user to after sign out\nsignout_redirect_url =\n\n# Set to true to attempt login with OAuth automatically, skipping the login screen.\n# This setting is ignored if multiple OAuth providers are configured.\n# Deprecated, use auto_login option for specific provider instead.\noauth_auto_login = false\n\n# OAuth state max age cookie duration in seconds. Defaults to 600 seconds.\noauth_state_cookie_max_age = 600\n\n# Skip forced assignment of OrgID 1 or 'auto_assign_org_id' for social logins\n# Deprecated, use skip_org_role_sync option for specific provider instead.\noauth_skip_org_role_update_sync = false\n\n# limit of api_key seconds to live before expiration\napi_key_max_seconds_to_live = -1\n\n# Set to true to enable SigV4 authentication option for HTTP-based datasources\nsigv4_auth_enabled = false\n\n# Set to true to enable verbose logging of SigV4 request signing\nsigv4_verbose_logging = false\n\n# Set to true to enable Azure authentication option for HTTP-based datasources\nazure_auth_enabled = false\n\n# Use email lookup in addition to the unique ID provided by the IdP\noauth_allow_insecure_email_lookup = false\n\n#################################### Anonymous Auth ######################\n[auth.anonymous]\n# enable anonymous access\nenabled = false\n\n# specify organization name that should be used for unauthenticated users\norg_name = Main Org.\n\n# specify role for unauthenticated users\norg_role = Viewer\n\n# mask the Grafana version number for unauthenticated users\nhide_version = false\n\n#################################### GitHub Auth #########################\n[auth.github]\nname = GitHub\nicon = github\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_id\nclient_secret =\nscopes = user:email,read:org\nauth_url = https://github.com/login/oauth/authorize\ntoken_url = https://github.com/login/oauth/access_token\napi_url = https://api.github.com/user\nallowed_domains =\nteam_ids =\nallowed_organizations =\nrole_attribute_path =\nrole_attribute_strict = false\nallow_assign_grafana_admin = false\nskip_org_role_sync = false\ntls_skip_verify_insecure = false\ntls_client_cert =\ntls_client_key =\ntls_client_ca =\n# GitHub OAuth apps does not provide refresh tokens and the access tokens never expires.\nuse_refresh_token = false\n\n#################################### GitLab Auth #########################\n[auth.gitlab]\nname = GitLab\nicon = gitlab\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_id\nclient_secret =\nscopes = openid email profile\nauth_url = https://gitlab.com/oauth/authorize\ntoken_url = https://gitlab.com/oauth/token\napi_url = https://gitlab.com/api/v4\nallowed_domains =\nallowed_groups =\nrole_attribute_path =\nrole_attribute_strict = false\nallow_assign_grafana_admin = false\nskip_org_role_sync = false\ntls_skip_verify_insecure = false\ntls_client_cert =\ntls_client_key =\ntls_client_ca =\nuse_pkce = true\nuse_refresh_token = true\n\n#################################### Google Auth #########################\n[auth.google]\nname = Google\nicon = google\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_client_id\nclient_secret =\nscopes = openid email profile\nauth_url = https://accounts.google.com/o/oauth2/v2/auth\ntoken_url = https://oauth2.googleapis.com/token\napi_url = https://openidconnect.googleapis.com/v1/userinfo\nallowed_domains =\nhosted_domain =\nallowed_groups =\nrole_attribute_path =\nrole_attribute_strict = false\nallow_assign_grafana_admin = false\nskip_org_role_sync = true\ntls_skip_verify_insecure = false\ntls_client_cert =\ntls_client_key =\ntls_client_ca =\nuse_pkce = true\nuse_refresh_token = true\n\n#################################### Grafana.com Auth ####################\n# legacy key names (so they work in env variables)\n[auth.grafananet]\nenabled = false\nallow_sign_up = true\nclient_id = some_id\nclient_secret =\nscopes = user:email\nallowed_organizations =\nuse_refresh_token = false\n\n[auth.grafana_com]\nname = Grafana.com\nicon = grafana\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_id\nclient_secret =\nscopes = user:email\nallowed_organizations =\nskip_org_role_sync = false\nuse_refresh_token = false\n\n#################################### Azure AD OAuth #######################\n[auth.azuread]\nname = Microsoft\nicon = microsoft\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_client_id\nclient_secret =\nscopes = openid email profile\nauth_url = https://login.microsoftonline.com/<tenant-id>/oauth2/v2.0/authorize\ntoken_url = https://login.microsoftonline.com/<tenant-id>/oauth2/v2.0/token\nallowed_domains =\nallowed_groups =\nallowed_organizations =\nrole_attribute_strict = false\nallow_assign_grafana_admin = false\nforce_use_graph_api = false\ntls_skip_verify_insecure = false\ntls_client_cert =\ntls_client_key =\ntls_client_ca =\nuse_pkce = true\nskip_org_role_sync = false\nuse_refresh_token = true\n\n#################################### Okta OAuth #######################\n[auth.okta]\nname = Okta\nicon = okta\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_id\nclient_secret =\nscopes = openid profile email groups\nauth_url = https://<tenant-id>.okta.com/oauth2/v1/authorize\ntoken_url = https://<tenant-id>.okta.com/oauth2/v1/token\napi_url = https://<tenant-id>.okta.com/oauth2/v1/userinfo\nallowed_domains =\nallowed_groups =\nrole_attribute_path =\nrole_attribute_strict = false\nallow_assign_grafana_admin = false\nskip_org_role_sync = false\ntls_skip_verify_insecure = false\ntls_client_cert =\ntls_client_key =\ntls_client_ca =\nuse_pkce = true\nuse_refresh_token = false\n\n#################################### Generic OAuth #######################\n[auth.generic_oauth]\nname = OAuth\nicon = signin\nenabled = false\nallow_sign_up = true\nauto_login = false\nclient_id = some_id\nclient_secret =\nscopes = user:email\nempty_scopes = false\nemail_attribute_name = email:primary\nemail_attribute_path =\nlogin_attribute_path =\nname_attribute_path =\nrole_attribute_path =\nrole_attribute_strict = false\ngroups_attribute_path =\nid_token_attribute_name =\nteam_ids_attribute_path =\nauth_url =\ntoken_url =\napi_url =\nteams_url =\nallowed_domains =\nallowed_groups =\nteam_ids =\nallowed_organizations =\ntls_skip_verify_insecure = false\ntls_client_cert =\ntls_client_key =\ntls_client_ca =\nuse_pkce = false\nauth_style =\nallow_assign_grafana_admin = false\nskip_org_role_sync = false\nuse_refresh_token = false\n\n#################################### Basic Auth ##########################\n[auth.basic]\nenabled = true\n\n#################################### Auth Proxy ##########################\n[auth.proxy]\nenabled = false\nheader_name = X-WEBAUTH-USER\nheader_property = username\nauto_sign_up = true\nsync_ttl = 60\nwhitelist =\nheaders =\nheaders_encoded = false\nenable_login_token = false\n\n#################################### Auth JWT ##########################\n[auth.jwt]\nenabled = false\nenable_login_token = false\nheader_name =\nemail_claim =\nusername_claim =\njwk_set_url =\njwk_set_file =\ncache_ttl = 60m\nexpect_claims = {}\nkey_file =\nkey_id =\nrole_attribute_path =\nrole_attribute_strict = false\nauto_sign_up = false\nurl_login = false\nallow_assign_grafana_admin = false\nskip_org_role_sync = false\n\n#################################### Auth LDAP ###########################\n[auth.ldap]\nenabled = false\nconfig_file = /etc/grafana/ldap.toml\nallow_sign_up = true\nskip_org_role_sync = false\n\n# LDAP background sync (Enterprise only)\n# At 1 am every day\nsync_cron = \"0 1 * * *\"\nactive_sync_enabled = true\n\n#################################### AWS ###########################\n[aws]\n# Enter a comma-separated list of allowed AWS authentication providers.\n# Options are: default (AWS SDK Default), keys (Access && secret key), credentials (Credentials field), ec2_iam_role (EC2 IAM Role)\nallowed_auth_providers = default,keys,credentials\n\n# Allow AWS users to assume a role using temporary security credentials.\n# If true, assume role will be enabled for all AWS authentication providers that are specified in aws_auth_providers\nassume_role_enabled = true\n\n# Specify max no of pages to be returned by the ListMetricPages API\nlist_metrics_page_limit = 500\n\n# Experimental, for use in Grafana Cloud only. Please do not set.\nexternal_id =\n\n#################################### Azure ###############################\n[azure]\n# Azure cloud environment where Grafana is hosted\n# Possible values are AzureCloud, AzureChinaCloud, AzureUSGovernment and AzureGermanCloud\n# Default value is AzureCloud (i.e. public cloud)\ncloud = AzureCloud\n\n# Specifies whether Grafana hosted in Azure service with Managed Identity configured (e.g. Azure Virtual Machines instance)\n# If enabled, the managed identity can be used for authentication of Grafana in Azure services\n# Disabled by default, needs to be explicitly enabled\nmanaged_identity_enabled = false\n\n# Client ID to use for user-assigned managed identity\n# Should be set for user-assigned identity and should be empty for system-assigned identity\nmanaged_identity_client_id =\n\n# Specifies whether Azure AD Workload Identity authentication should be enabled in datasources that support it\n# For more documentation on Azure AD Workload Identity, review this documentation:\n# https://azure.github.io/azure-workload-identity/docs/\n# Disabled by default, needs to be explicitly enabled\nworkload_identity_enabled = false\n\n# Tenant ID of the Azure AD Workload Identity\n# Allows to override default tenant ID of the Azure AD identity associated with the Kubernetes service account\nworkload_identity_tenant_id =\n\n# Client ID of the Azure AD Workload Identity\n# Allows to override default client ID of the Azure AD identity associated with the Kubernetes service account\nworkload_identity_client_id =\n\n# Custom path to token file for the Azure AD Workload Identity\n# Allows to set a custom path to the projected service account token file\nworkload_identity_token_file =\n\n# Specifies whether user identity authentication (on behalf of currently signed-in user) should be enabled in datasources\n# that support it (requires AAD authentication)\n# Disabled by default, needs to be explicitly enabled\nuser_identity_enabled = false\n\n# Override token URL for Azure Active Directory\n# By default is the same as token URL configured for AAD authentication settings\nuser_identity_token_url =\n\n# Override ADD application ID which would be used to exchange users token to an access token for the datasource\n# By default is the same as used in AAD authentication or can be set to another application (for OBO flow)\nuser_identity_client_id =\n\n# Override the AAD application client secret\n# By default is the same as used in AAD authentication or can be set to another application (for OBO flow)\nuser_identity_client_secret =\n\n#################################### Role-based Access Control ###########\n[rbac]\n# If enabled, cache permissions in a in memory cache\npermission_cache = true\n\n# Reset basic roles permissions on boot\n# Warning left to true, basic roles permissions will be reset on every boot\nreset_basic_roles = false\n\n# Validate permissions' action and scope on role creation and update\npermission_validation_enabled = true\n\n#################################### SMTP / Emailing #####################\n[smtp]\nenabled = false\nhost = localhost:25\nuser =\n# If the password contains # or ; you have to wrap it with triple quotes. Ex \"\"\"#password;\"\"\"\npassword =\ncert_file =\nkey_file =\nskip_verify = false\nfrom_address = admin@grafana.localhost\nfrom_name = Grafana\nehlo_identity =\nstartTLS_policy =\n\n[emails]\nwelcome_email_on_sign_up = false\ntemplates_pattern = emails/*.html, emails/*.txt\ncontent_types = text/html\n\n#################################### Logging ##########################\n[log]\n# Either \"console\", \"file\", \"syslog\". Default is console and file\n# Use space to separate multiple modes, e.g. \"console file\"\nmode = console file\n\n# Either \"debug\", \"info\", \"warn\", \"error\", \"critical\", default is \"info\"\nlevel = info\n\n# optional settings to set different levels for specific loggers. Ex filters = sqlstore:debug\nfilters =\n\n# Set the default error message shown to users. This message is displayed instead of sensitive backend errors which should be obfuscated.\nuser_facing_default_error = \"please inspect Grafana server log for details\"\n\n# For \"console\" mode only\n[log.console]\nlevel =\n\n# log line format, valid options are text, console and json\nformat = console\n\n# For \"file\" mode only\n[log.file]\nlevel =\n\n# log line format, valid options are text, console and json\nformat = text\n\n# This enables automated log rotate(switch of following options), default is true\nlog_rotate = true\n\n# Max line number of single file, default is 1000000\nmax_lines = 1000000\n\n# Max size shift of single file, default is 28 means 1 << 28, 256MB\nmax_size_shift = 28\n\n# Segment log daily, default is true\ndaily_rotate = true\n\n# Expired days of log file(delete after max days), default is 7\nmax_days = 7\n\n[log.syslog]\nlevel =\n\n# log line format, valid options are text, console and json\nformat = text\n\n# Syslog network type and address. This can be udp, tcp, or unix. If left blank, the default unix endpoints will be used.\nnetwork =\naddress =\n\n# Syslog facility. user, daemon and local0 through local7 are valid.\nfacility =\n\n# Syslog tag. By default, the process' argv[0] is used.\ntag =\n\n[log.frontend]\n# Should Faro javascript agent be initialized\nenabled = false\n\n# Custom HTTP endpoint to send events to. Default will log the events to stdout.\ncustom_endpoint =\n\n# Requests per second limit enforced per an extended period, for Grafana backend log ingestion endpoint (/log).\nlog_endpoint_requests_per_second_limit = 3\n\n# Max requests accepted per short interval of time for Grafana backend log ingestion endpoint (/log)\nlog_endpoint_burst_limit = 15\n\n# Should error instrumentation be enabled, only affects Grafana Javascript Agent\ninstrumentations_errors_enabled = true\n\n# Should console instrumentation be enabled, only affects Grafana Javascript Agent\ninstrumentations_console_enabled = false\n\n# Should webvitals instrumentation be enabled, only affects Grafana Javascript Agent\ninstrumentations_webvitals_enabled = false\n\n# Api Key, only applies to Grafana Javascript Agent provider\napi_key =\n\n#################################### Usage Quotas ########################\n[quota]\nenabled = false\n\n#### set quotas to -1 to make unlimited. ####\n# limit number of users per Org.\norg_user = 10\n\n# limit number of dashboards per Org.\norg_dashboard = 100\n\n# limit number of data_sources per Org.\norg_data_source = 10\n\n# limit number of api_keys per Org.\norg_api_key = 10\n\n# limit number of alerts per Org.\norg_alert_rule = 100\n\n# limit number of orgs a user can create.\nuser_org = 10\n\n# Global limit of users.\nglobal_user = -1\n\n# global limit of orgs.\nglobal_org = -1\n\n# global limit of dashboards\nglobal_dashboard = -1\n\n# global limit of api_keys\nglobal_api_key = -1\n\n# global limit on number of logged in users.\nglobal_session = -1\n\n# global limit of alerts\nglobal_alert_rule = -1\n\n# global limit of files uploaded to the SQL DB\nglobal_file = 1000\n\n# global limit of correlations\nglobal_correlations = -1\n\n#################################### Unified Alerting ####################\n[unified_alerting]\n# Enable the Unified Alerting sub-system and interface. When enabled we'll migrate all of your alert rules and notification channels to the new system. New alert rules will be created and your notification channels will be converted into an Alertmanager configuration. Previous data is preserved to enable backwards compatibility but new data is removed when switching. When this configuration section and flag are not defined, the state is defined at runtime. See the documentation for more details.\nenabled =\n\n# Comma-separated list of organization IDs for which to disable unified alerting. Only supported if unified alerting is enabled.\ndisabled_orgs =\n\n# Specify the frequency of polling for admin config changes.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nadmin_config_poll_interval = 60s\n\n# Specify the frequency of polling for Alertmanager config changes.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nalertmanager_config_poll_interval = 60s\n\n# The redis server address that should be connected to.\nha_redis_address =\n\n# The username that should be used to authenticate with the redis server.\nha_redis_username =\n\n# The password that should be used to authenticate with the redis server.\nha_redis_password =\n\n# The redis database, by default it's 0.\nha_redis_db =\n\n# A prefix that is used for every key or channel that is created on the redis server\n# as part of HA for alerting.\nha_redis_prefix =\n\n# The name of the cluster peer that will be used as identifier. If none is\n# provided, a random one will be generated.\nha_redis_peer_name =\n\n# The maximum number of simultaneous redis connections.\nha_redis_max_conns = 5\n\n# Listen address/hostname and port to receive unified alerting messages for other Grafana instances. The port is used for both TCP and UDP. It is assumed other Grafana instances are also running on the same port.\nha_listen_address = \"0.0.0.0:9094\"\n\n# Explicit address/hostname and port to advertise other Grafana instances. The port is used for both TCP and UDP.\nha_advertise_address = \"\"\n\n# Comma-separated list of initial instances (in a format of host:port) that will form the HA cluster. Configuring this setting will enable High Availability mode for alerting.\nha_peers = \"\"\n\n# Time to wait for an instance to send a notification via the Alertmanager. In HA, each Grafana instance will\n# be assigned a position (e.g. 0, 1). We then multiply this position with the timeout to indicate how long should\n# each instance wait before sending the notification to take into account replication lag.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nha_peer_timeout = 15s\n\n# The label is an optional string to include on each packet and stream.\n# It uniquely identifies the cluster and prevents cross-communication\n# issues when sending gossip messages in an enviromenet with multiple clusters.\nha_label =\n\n# The interval between sending gossip messages. By lowering this value (more frequent) gossip messages are propagated\n# across cluster more quickly at the expense of increased bandwidth usage.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nha_gossip_interval = 200ms\n\n# The interval between gossip full state syncs. Setting this interval lower (more frequent) will increase convergence speeds\n# across larger clusters at the expense of increased bandwidth usage.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nha_push_pull_interval = 60s\n\n# Enable or disable alerting rule execution. The alerting UI remains visible. This option has a legacy version in the `[alerting]` section that takes precedence.\nexecute_alerts = true\n\n# Alert evaluation timeout when fetching data from the datasource. This option has a legacy version in the `[alerting]` section that takes precedence.\n# The timeout string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nevaluation_timeout = 30s\n\n# Number of times we'll attempt to evaluate an alert rule before giving up on that evaluation. This option has a legacy version in the `[alerting]` section that takes precedence.\nmax_attempts = 3\n\n# Minimum interval to enforce between rule evaluations. Rules will be adjusted if they are less than this value or if they are not multiple of the scheduler interval (10s). Higher values can help with resource management as we'll schedule fewer evaluations over time. This option has a legacy version in the `[alerting]` section that takes precedence.\n# The interval string is a possibly signed sequence of decimal numbers, followed by a unit suffix (ms, s, m, h, d), e.g. 30s or 1m.\nmin_interval = 10s\n\n# This is an experimental option to add parallelization to saving alert states in the database.\n# It configures the maximum number of concurrent queries per rule evaluated. The default value is 1\n# (concurrent queries per rule disabled).\nmax_state_save_concurrency = 1\n\n[unified_alerting.screenshots]\n# Enable screenshots in notifications. You must have either installed the Grafana image rendering\n# plugin, or set up Grafana to use a remote rendering service.\n# For more information on configuration options, refer to [rendering].\ncapture = false\n\n# The timeout for capturing screenshots. If a screenshot cannot be captured within the timeout then\n# the notification is sent without a screenshot. The maximum duration is 30 seconds. This timeout\n# should be less than the minimum Interval of all Evaluation Groups to avoid back pressure on alert\n# rule evaluation.\ncapture_timeout = 10s\n\n# The maximum number of screenshots that can be taken at the same time. This option is different from\n# concurrent_render_request_limit as max_concurrent_screenshots sets the number of concurrent screenshots\n# that can be taken at the same time for all firing alerts where as concurrent_render_request_limit sets\n# the total number of concurrent screenshots across all Grafana services.\nmax_concurrent_screenshots = 5\n\n# Uploads screenshots to the local Grafana server or remote storage such as Azure, S3 and GCS. Please\n# see [external_image_storage] for further configuration options. If this option is false then\n# screenshots will be persisted to disk for up to temp_data_lifetime.\nupload_external_image_storage = false\n\n[unified_alerting.reserved_labels]\n# Comma-separated list of reserved labels added by the Grafana Alerting engine that should be disabled.\n# For example: `disabled_labels=grafana_folder`\ndisabled_labels =\n\n[unified_alerting.state_history]\n# Enable the state history functionality in Unified Alerting. The previous states of alert rules will be visible in panels and in the UI.\nenabled = true\n\n# Select which pluggable state history backend to use. Either \"annotations\", \"loki\", or \"multiple\"\n# \"loki\" writes state history to an external Loki instance. \"multiple\" allows history to be written to multiple backends at once.\n# Defaults to \"annotations\".\nbackend =\n\n# For \"multiple\" only.\n# Indicates the main backend used to serve state history queries.\n# Either \"annotations\" or \"loki\"\nprimary =\n\n# For \"multiple\" only.\n# Comma-separated list of additional backends to write state history data to.\nsecondaries =\n\n# For \"loki\" only.\n# URL of the external Loki instance.\n# Either \"loki_remote_url\", or both of \"loki_remote_read_url\" and \"loki_remote_write_url\" is required for the \"loki\" backend.\nloki_remote_url =\n\n# For \"loki\" only.\n# URL of the external Loki's read path. To be used in configurations where Loki has separated read and write URLs.\n# Either \"loki_remote_url\", or both of \"loki_remote_read_url\" and \"loki_remote_write_url\" is required for the \"loki\" backend.\nloki_remote_read_url =\n\n# For \"loki\" only.\n# URL of the external Loki's write path. To be used in configurations where Loki has separated read and write URLs.\n# Either \"loki_remote_url\", or both of \"loki_remote_read_url\" and \"loki_remote_write_url\" is required for the \"loki\" backend.\nloki_remote_write_url =\n\n# For \"loki\" only.\n# Optional tenant ID to attach to requests sent to Loki.\nloki_tenant_id =\n\n# For \"loki\" only.\n# Optional username for basic authentication on requests sent to Loki. Can be left blank to disable basic auth.\nloki_basic_auth_username =\n\n# For \"loki\" only.\n# Optional password for basic authentication on requests sent to Loki. Can be left blank.\nloki_basic_auth_password =\n\n[unified_alerting.state_history.external_labels]\n# Optional extra labels to attach to outbound state history records or log streams.\n# Any number of label key-value-pairs can be provided.\n#\n# ex.\n# mylabelkey = mylabelvalue\n\n# NOTE: this configuration options are not used yet.\n[remote.alertmanager]\n\n# Enable the use of the configured remote Alertmanager and disable the internal one.\n# The default value is `false`.\nenabled = false\n\n# URL of the remote Alertmanager that will replace the internal one.\n# Required if `enabled` is set to `true`.\nurl =\n\n# Tenant ID to use in requests to the Alertmanager.\n# It will also be used for the basic auth username.\ntenant =\n\n# Optional password for basic authentication.\n# If not present, the tenant ID will be set in the X-Scope-OrgID header.\npassword =\n\n#################################### Alerting ############################\n[alerting]\n# Enable the legacy alerting sub-system and interface. If Unified Alerting is already enabled and you try to go back to legacy alerting, all data that is part of Unified Alerting will be deleted. When this configuration section and flag are not defined, the state is defined at runtime. See the documentation for more details.\nenabled =\n\n# Makes it possible to turn off alert execution but alerting UI is visible\nexecute_alerts = true\n\n# Default setting for new alert rules. Defaults to categorize error and timeouts as alerting. (alerting, keep_state)\nerror_or_timeout = alerting\n\n# Default setting for how Grafana handles nodata or null values in alerting. (alerting, no_data, keep_state, ok)\nnodata_or_nullvalues = no_data\n\n# Alert notifications can include images, but rendering many images at the same time can overload the server\n# This limit will protect the server from render overloading and make sure notifications are sent out quickly\nconcurrent_render_limit = 5\n\n# Default setting for alert calculation timeout. Default value is 30\nevaluation_timeout_seconds = 30\n\n# Default setting for alert notification timeout. Default value is 30\nnotification_timeout_seconds = 30\n\n# Default setting for max attempts to sending alert notifications. Default value is 3\nmax_attempts = 3\n\n# Makes it possible to enforce a minimal interval between evaluations, to reduce load on the backend\nmin_interval_seconds = 1\n\n# Configures for how long alert annotations are stored. Default is 0, which keeps them forever.\n# This setting should be expressed as an duration. Ex 6h (hours), 10d (days), 2w (weeks), 1M (month).\nmax_annotation_age =\n\n# Configures max number of alert annotations that Grafana stores. Default value is 0, which keeps all alert annotations.\nmax_annotations_to_keep =\n\n#################################### Annotations #########################\n[annotations]\n# Configures the batch size for the annotation clean-up job. This setting is used for dashboard, API, and alert annotations.\ncleanupjob_batchsize = 100\n\n# Enforces the maximum allowed length of the tags for any newly introduced annotations. It can be between 500 and 4096 inclusive (which is the respective's column length). Default value is 500.\n# Setting it to a higher value would impact performance therefore is not recommended.\ntags_length = 500\n\n[annotations.dashboard]\n# Dashboard annotations means that annotations are associated with the dashboard they are created on.\n\n# Configures how long dashboard annotations are stored. Default is 0, which keeps them forever.\n# This setting should be expressed as a duration. Examples: 6h (hours), 10d (days), 2w (weeks), 1M (month).\nmax_age =\n\n# Configures max number of dashboard annotations that Grafana stores. Default value is 0, which keeps all dashboard annotations.\nmax_annotations_to_keep =\n\n[annotations.api]\n# API annotations means that the annotations have been created using the API without any\n# association with a dashboard.\n\n# Configures how long Grafana stores API annotations. Default is 0, which keeps them forever.\n# This setting should be expressed as a duration. Examples: 6h (hours), 10d (days), 2w (weeks), 1M (month).\nmax_age =\n\n# Configures max number of API annotations that Grafana keeps. Default value is 0, which keeps all API annotations.\nmax_annotations_to_keep =\n\n#################################### Explore #############################\n[explore]\n# Enable the Explore section\nenabled = true\n\n#################################### Help #############################\n[help]\n# Enable the Help section\nenabled = true\n\n#################################### Profile #############################\n[profile]\n# Enable the Profile section\nenabled = true\n\n#################################### News #############################\n[news]\n# Enable the news feed section\nnews_feed_enabled = true\n\n#################################### Query #############################\n[query]\n# Set the number of data source queries that can be executed concurrently in mixed queries. Default is the number of CPUs.\nconcurrent_query_limit =\n\n#################################### Query History #############################\n[query_history]\n# Enable the Query history\nenabled = true\n\n#################################### Internal Grafana Metrics ############\n# Metrics available at HTTP URL /metrics and /metrics/plugins/:pluginId\n[metrics]\nenabled              = true\ninterval_seconds     = 10\n# Disable total stats (stat_totals_*) metrics to be generated\ndisable_total_stats = false\n# The interval at which the total stats collector will update the stats. Default is 1800 seconds.\ntotal_stats_collector_interval_seconds = 1800\n\n#If both are set, basic auth will be required for the metrics endpoints.\nbasic_auth_username =\nbasic_auth_password =\n\n# Metrics environment info adds dimensions to the `grafana_environment_info` metric, which\n# can expose more information about the Grafana instance.\n[metrics.environment_info]\n#exampleLabel1 = exampleValue1\n#exampleLabel2 = exampleValue2\n\n# Send internal Grafana metrics to graphite\n[metrics.graphite]\n# Enable by setting the address setting (ex localhost:2003)\naddress =\nprefix = prod.grafana.%(instance_name)s.\n\n#################################### Grafana.com integration  ##########################\n[grafana_net]\nurl = https://grafana.com\n\n[grafana_com]\nurl = https://grafana.com\napi_url = https://grafana.com/api\n\n#################################### Distributed tracing ############\n# Opentracing is deprecated use opentelemetry instead\n[tracing.jaeger]\n# jaeger destination (ex localhost:6831)\naddress =\n# tag that will always be included in when creating new spans. ex (tag1:value1,tag2:value2)\nalways_included_tag =\n# Type specifies the type of the sampler: const, probabilistic, rateLimiting, or remote\nsampler_type = const\n# jaeger samplerconfig param\n# for \"const\" sampler, 0 or 1 for always false/true respectively\n# for \"probabilistic\" sampler, a probability between 0 and 1\n# for \"rateLimiting\" sampler, the number of spans per second\n# for \"remote\" sampler, param is the same as for \"probabilistic\"\n# and indicates the initial sampling rate before the actual one\n# is received from the mothership\nsampler_param = 1\n# sampling_server_url is the URL of a sampling manager providing a sampling strategy.\nsampling_server_url =\n# Whether or not to use Zipkin span propagation (x-b3- HTTP headers).\nzipkin_propagation = false\n# Setting this to true disables shared RPC spans.\n# Not disabling is the most common setting when using Zipkin elsewhere in your infrastructure.\ndisable_shared_zipkin_spans = false\n\n[tracing.opentelemetry]\n\n# attributes that will always be included in when creating new spans. ex (key1:value1,key2:value2)\ncustom_attributes =\n# Type specifies the type of the sampler: const, probabilistic, rateLimiting, or remote\nsampler_type =\n# Sampler configuration parameter\n# for \"const\" sampler, 0 or 1 for always false/true respectively\n# for \"probabilistic\" sampler, a probability between 0.0 and 1.0\n# for \"rateLimiting\" sampler, the number of spans per second\n# for \"remote\" sampler, param is the same as for \"probabilistic\"\n#   and indicates the initial sampling rate before the actual one\n#   is received from the sampling server (set at sampling_server_url)\nsampler_param =\n# specifies the URL of the sampling server when sampler_type is remote\nsampling_server_url =\n\n[tracing.opentelemetry.jaeger]\n# jaeger destination (ex http://localhost:14268/api/traces)\naddress =\n# Propagation specifies the text map propagation format: w3c, jaeger\npropagation =\n\n# This is a configuration for OTLP exporter with GRPC protocol\n[tracing.opentelemetry.otlp]\n# otlp destination (ex localhost:4317)\naddress =\n# Propagation specifies the text map propagation format: w3c, jaeger\npropagation =\n\n#################################### External Image Storage ##############\n[external_image_storage]\n# Used for uploading images to public servers so they can be included in slack/email messages.\n# You can choose between (s3, webdav, gcs, azure_blob, local)\nprovider =\n\n[external_image_storage.s3]\nendpoint =\npath_style_access =\nbucket_url =\nbucket =\nregion =\npath =\naccess_key =\nsecret_key =\n\n[external_image_storage.webdav]\nurl =\nusername =\npassword =\npublic_url =\n\n[external_image_storage.gcs]\nkey_file =\nbucket =\npath =\nenable_signed_urls = false\nsigned_url_expiration =\n\n[external_image_storage.azure_blob]\naccount_name =\naccount_key =\ncontainer_name =\nsas_token_expiration_days =\n\n[external_image_storage.local]\n# does not require any configuration\n\n[rendering]\n# Options to configure a remote HTTP image rendering service, e.g. using https://github.com/grafana/grafana-image-renderer.\n# URL to a remote HTTP image renderer service, e.g. http://localhost:8081/render, will enable Grafana to render panels and dashboards to PNG-images using HTTP requests to an external service.\nserver_url =\n# If the remote HTTP image renderer service runs on a different server than the Grafana server you may have to configure this to a URL where Grafana is reachable, e.g. http://grafana.domain/.\ncallback_url =\n# An auth token that will be sent to and verified by the renderer. The renderer will deny any request without an auth token matching the one configured on the renderer side.\nrenderer_token = -\n# Concurrent render request limit affects when the /render HTTP endpoint is used. Rendering many images at the same time can overload the server,\n# which this setting can help protect against by only allowing a certain amount of concurrent requests.\nconcurrent_render_request_limit = 30\n# Determines the lifetime of the render key used by the image renderer to access and render Grafana.\n# This setting should be expressed as a duration. Examples: 10s (seconds), 5m (minutes), 2h (hours).\n# Default is 5m. This should be more than enough for most deployments.\n# Change the value only if image rendering is failing and you see `Failed to get the render key from cache` in Grafana logs.\nrender_key_lifetime = 5m\n\n[panels]\n# here for to support old env variables, can remove after a few months\nenable_alpha = false\ndisable_sanitize_html = false\n\n[plugins]\nenable_alpha = false\napp_tls_skip_verify_insecure = false\n# Enter a comma-separated list of plugin identifiers to identify plugins to load even if they are unsigned. Plugins with modified signatures are never loaded.\nallow_loading_unsigned_plugins =\n# Enable or disable installing / uninstalling / updating plugins directly from within Grafana.\nplugin_admin_enabled = true\nplugin_admin_external_manage_enabled = false\nplugin_catalog_url = https://grafana.com/grafana/plugins/\n# Enter a comma-separated list of plugin identifiers to hide in the plugin catalog.\nplugin_catalog_hidden_plugins =\n# Log all backend requests for core and external plugins.\nlog_backend_requests = false\n# Disable download of the public key for verifying plugin signature.\npublic_key_retrieval_disabled = false\n# Force download of the public key for verifying plugin signature on startup. If disabled, the public key will be retrieved every 10 days.\n# Requires public_key_retrieval_disabled to be false to have any effect.\npublic_key_retrieval_on_startup = false\n# Enter a comma-separated list of plugin identifiers to avoid loading (including core plugins). These plugins will be hidden in the catalog.\ndisable_plugins =\n\n#################################### Grafana Live ##########################################\n[live]\n# max_connections to Grafana Live WebSocket endpoint per Grafana server instance. See Grafana Live docs\n# if you are planning to make it higher than default 100 since this can require some OS and infrastructure\n# tuning. 0 disables Live, -1 means unlimited connections.\nmax_connections = 100\n\n# allowed_origins is a comma-separated list of origins that can establish connection with Grafana Live.\n# If not set then origin will be matched over root_url. Supports wildcard symbol \"*\".\nallowed_origins =\n\n# engine defines an HA (high availability) engine to use for Grafana Live. By default no engine used - in\n# this case Live features work only on a single Grafana server.\n# Available options: \"redis\".\n# Setting ha_engine is an EXPERIMENTAL feature.\nha_engine =\n\n# ha_engine_address sets a connection address for Live HA engine. Depending on engine type address format can differ.\n# For now we only support Redis connection address in \"host:port\" format.\n# This option is EXPERIMENTAL.\nha_engine_address = \"127.0.0.1:6379\"\n\n# ha_engine_password allows setting an optional password to authenticate with the engine\nha_engine_password = \"\"\n\n#################################### Grafana Image Renderer Plugin ##########################\n[plugin.grafana-image-renderer]\n# Instruct headless browser instance to use a default timezone when not provided by Grafana, e.g. when rendering panel image of alert.\n# See ICU’s metaZones.txt (https://cs.chromium.org/chromium/src/third_party/icu/source/data/misc/metaZones.txt) for a list of supported\n# timezone IDs. Fallbacks to TZ environment variable if not set.\nrendering_timezone =\n\n# Instruct headless browser instance to use a default language when not provided by Grafana, e.g. when rendering panel image of alert.\n# Please refer to the HTTP header Accept-Language to understand how to format this value, e.g. 'fr-CH, fr;q=0.9, en;q=0.8, de;q=0.7, *;q=0.5'.\nrendering_language =\n\n# Instruct headless browser instance to use a default device scale factor when not provided by Grafana, e.g. when rendering panel image of alert.\n# Default is 1. Using a higher value will produce more detailed images (higher DPI), but will require more disk space to store an image.\nrendering_viewport_device_scale_factor =\n\n# Instruct headless browser instance whether to ignore HTTPS errors during navigation. Per default HTTPS errors are not ignored. Due to\n# the security risk it's not recommended to ignore HTTPS errors.\nrendering_ignore_https_errors =\n\n# Instruct headless browser instance whether to capture and log verbose information when rendering an image. Default is false and will\n# only capture and log error messages. When enabled, debug messages are captured and logged as well.\n# For the verbose information to be included in the Grafana server log you have to adjust the rendering log level to debug, configure\n# [log].filter = rendering:debug.\nrendering_verbose_logging =\n\n# Instruct headless browser instance whether to output its debug and error messages into running process of remote rendering service.\n# Default is false. This can be useful to enable (true) when troubleshooting.\nrendering_dumpio =\n\n# Additional arguments to pass to the headless browser instance. Default is --no-sandbox. The list of Chromium flags can be found\n# here (https://peter.sh/experiments/chromium-command-line-switches/). Multiple arguments is separated with comma-character.\nrendering_args =\n\n# You can configure the plugin to use a different browser binary instead of the pre-packaged version of Chromium.\n# Please note that this is not recommended, since you may encounter problems if the installed version of Chrome/Chromium is not\n# compatible with the plugin.\nrendering_chrome_bin =\n\n# Instruct how headless browser instances are created. Default is 'default' and will create a new browser instance on each request.\n# Mode 'clustered' will make sure that only a maximum of browsers/incognito pages can execute concurrently.\n# Mode 'reusable' will have one browser instance and will create a new incognito page on each request.\nrendering_mode =\n\n# When rendering_mode = clustered, you can instruct how many browsers or incognito pages can execute concurrently. Default is 'browser'\n# and will cluster using browser instances.\n# Mode 'context' will cluster using incognito pages.\nrendering_clustering_mode =\n# When rendering_mode = clustered, you can define the maximum number of browser instances/incognito pages that can execute concurrently. Default is '5'.\nrendering_clustering_max_concurrency =\n# When rendering_mode = clustered, you can specify the duration a rendering request can take before it will time out. Default is `30` seconds.\nrendering_clustering_timeout =\n\n# Limit the maximum viewport width, height and device scale factor that can be requested.\nrendering_viewport_max_width =\nrendering_viewport_max_height =\nrendering_viewport_max_device_scale_factor =\n\n# Change the listening host and port of the gRPC server. Default host is 127.0.0.1 and default port is 0 and will automatically assign\n# a port not in use.\ngrpc_host =\ngrpc_port =\n\n[enterprise]\nlicense_path =\n\n[feature_toggles]\n# there are currently two ways to enable feature toggles in the `grafana.ini`.\n# you can either pass an array of feature you want to enable to the `enable` field or\n# configure each toggle by setting the name of the toggle to true/false. Toggles set to true/false\n# will take precedence over toggles in the `enable` list.\n\n# enable = feature1,feature2\nenable =\n\n# Some features are enabled by default, see:\n# https://grafana.com/docs/grafana/next/setup-grafana/configure-grafana/feature-toggles/\n# To enable features by default, set `Expression:  \"true\"` in:\n# https://github.com/grafana/grafana/blob/main/pkg/services/featuremgmt/registry.go\n\n# feature1 = true\n# feature2 = false\n\n[date_formats]\n# For information on what formatting patterns that are supported https://momentjs.com/docs/#/displaying/\n\n# Default system date format used in time range picker and other places where full time is displayed\nfull_date = YYYY-MM-DD HH:mm:ss\n\n# Used by graph and other places where we only show small intervals\ninterval_second = HH:mm:ss\ninterval_minute = HH:mm\ninterval_hour = MM/DD HH:mm\ninterval_day = MM/DD\ninterval_month = YYYY-MM\ninterval_year = YYYY\n\n# Experimental feature\nuse_browser_locale = false\n\n# Default timezone for user preferences. Options are 'browser' for the browser local timezone or a timezone name from IANA Time Zone database, e.g. 'UTC' or 'Europe/Amsterdam' etc.\ndefault_timezone = browser\n\n[expressions]\n# Enable or disable the expressions functionality.\nenabled = true\n\n[geomap]\n# Set the JSON configuration for the default basemap\ndefault_baselayer_config =\n\n# Enable or disable loading other base map layers\nenable_custom_baselayers = true\n\n#################################### Support Bundles #####################################\n[support_bundles]\n# Enable support bundle creation (default: true)\nenabled = true\n# Only server admins can generate and view support bundles (default: true)\nserver_admin_only = true\n# If set, bundles will be encrypted with the provided public keys separated by whitespace\npublic_keys = \"\"\n\n#################################### Storage ################################################\n\n[storage]\n# Allow uploading SVG files without sanitization.\nallow_unsanitized_svg_upload = false\n\n\n#################################### Search ################################################\n\n[search]\n# Defines the number of dashboards loaded at once in a batch during a full reindex.\n# This is a temporary settings that might be removed in the future.\ndashboard_loading_batch_size = 200\n\n# Defines the frequency of a full search reindex.\n# This is a temporary settings that might be removed in the future.\nfull_reindex_interval = 5m\n\n# Defines the frequency of partial index updates based on recent changes such as dashboard updates.\n# This is a temporary settings that might be removed in the future.\nindex_update_interval = 10s\n\n\n# Move an app plugin referenced by its id (including all its pages) to a specific navigation section\n# Format: <Plugin ID> = <Section ID> <Sort Weight>\n[navigation.app_sections]\n\n# Move a specific app plugin page (referenced by its `path` field) to a specific navigation section\n# Format: <Page URL> = <Section ID> <Sort Weight>\n[navigation.app_standalone_pages]\n\n\n#################################### Secure Socks5 Datasource Proxy #####################################\n[secure_socks_datasource_proxy]\nenabled = false\nroot_ca_cert =\nclient_key =\nclient_cert =\nserver_name =\n# The address of the socks5 proxy datasources should connect to\nproxy_address =\n# Determines if the secure socks proxy should be shown on the datasources page, defaults to true if the feature is enabled\nshow_ui = true\n\n################################## Feature Management ##############################################\n# Options to configure the experimental Feature Toggle Admin Page feature, which is behind the `featureToggleAdminPage` feature toggle. Use at your own risk.\n[feature_management]\n# Allows editing of feature toggles in the feature management page\nallow_editing = false\n\n# Allow customization of URL for the controller that manages feature toggles\nupdate_webhook =\n\n# Allow configuring an auth token for feature management update requests\nupdate_webhook_token =\n\n# Hides specific feature toggles from the feature management page\nhidden_toggles =\n\n# Disables updating specific feature toggles in the feature management page\nread_only_toggles ="
---
# Source: homelab/templates/observability/loki/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-configs
data:
  configuration.yaml: ""
---
# Source: homelab/templates/observability/prometheus/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-configs
data:
  configuration.yaml: "global:\n  scrape_interval:     15s\n  evaluation_interval: 15s\n\nrule_files:\n  # - \"first.rules\"\n  # - \"second.rules\"\n\nscrape_configs:\n  - job_name: prometheus\n    static_configs:\n      - targets: \n        - \"192.168.1.68:9100\" # node-exporter: thinkcentre\n        - \"192.168.1.69:9100\" # node-exporter: main array"
---
# Source: homelab/templates/observability/promtail/cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-configs
data:
  promtail.yaml: "scrape_configs:\n  - job_name: pods\n    static_configs:\n      - targets: \n          - localhost\n        labels: \n          job: pod\n          __path__: /var/log/containers/*.log\n    pipeline_stages:\n      - cri: {}\n      - match:\n          selector: '{job=\"pod\"}'\n          stages:\n            - regex:\n                source: filename\n                expression: (\\/var\\/log\\/containers\\/)(?P<containerName>.+)(-.+-.+_default_.+)\n            - labels:\n                containerName:\n            - labeldrop:\n                - filename\n\nclients: \n  - url: 'http://loki/loki/api/v1/push'"
---
# Source: homelab/templates/nfs/pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: bulk-nfs
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: bulk-nfs
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /bulk-pool/nfs
    server: 192.168.1.69
---
# Source: homelab/templates/nfs/pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: cache-nfs
spec:
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: cache-nfs
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /cache-pool/nfs
    server: 192.168.1.69
---
# Source: homelab/templates/nfs/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: bulk-nfs
spec:
  storageClassName: bulk-nfs
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 500Mi
---
# Source: homelab/templates/nfs/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: cache-nfs
spec:
  storageClassName: cache-nfs
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 500Mi
---
# Source: homelab/charts/reloader/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1

kind: ClusterRole
metadata:
  annotations:
    meta.helm.sh/release-namespace: "default"
    meta.helm.sh/release-name: "bingus"
  labels:
    app: bingus-reloader
    chart: "reloader-1.0.50"
    release: "bingus"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
  name: bingus-reloader-role
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
      - configmaps
    verbs:
      - list
      - get
      - watch
  - apiGroups:
      - "apps"
    resources:
      - deployments
      - daemonsets
      - statefulsets
    verbs:
      - list
      - get
      - update
      - patch
  - apiGroups:
      - "extensions"
    resources:
      - deployments
      - daemonsets
    verbs:
      - list
      - get
      - update
      - patch
  - apiGroups:
      - "batch"
    resources:
      - cronjobs
    verbs:
      - list
      - get
  - apiGroups:
      - "batch"
    resources:
      - jobs
    verbs:
      - create
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
---
# Source: homelab/charts/reloader/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1

kind: ClusterRoleBinding
metadata:
  annotations:
    meta.helm.sh/release-namespace: "default"
    meta.helm.sh/release-name: "bingus"
  labels:
    app: bingus-reloader
    chart: "reloader-1.0.50"
    release: "bingus"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
  name: bingus-reloader-role-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: bingus-reloader-role
subjects:
  - kind: ServiceAccount
    name: bingus-reloader
    namespace: default
---
# Source: homelab/templates/authelia/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: authelia
spec:
  selector:
    app: authelia
  ports:
    - protocol: TCP
      name: http
      port: 80
      targetPort: 9091

    - protocol: TCP
      name: prom
      port: 9959
      targetPort: 9959
---
# Source: homelab/templates/autobrr/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: autobrr
spec:
  selector:
    app: autobrr
    app.kubernetes.io/name: autobrr
  ports:
    - protocol: TCP
      port: 80
      targetPort: 7474
---
# Source: homelab/templates/calibre/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: calibre
spec:
  selector:
    app: calibre
    app.kubernetes.io/name: calibre
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8083
---
# Source: homelab/templates/gitea/app/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea
spec:
  selector:
    app: gitea
    app.kubernetes.io/name: gitea
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
---
# Source: homelab/templates/jellyfin/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: jellyfin
spec:
  selector:
    app: jellyfin
    app.kubernetes.io/name: jellyfin
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8096
---
# Source: homelab/templates/miniflux/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: miniflux
spec:
  selector:
    app: miniflux
    app.kubernetes.io/name: miniflux
  ports:
    - protocol: TCP
      name: miniflux-client
      port: 80
      targetPort: 8080

    - protocol: TCP
      name: miniflux-db
      port: 5432
      targetPort: 5432
---
# Source: homelab/templates/nginx/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx
spec: 
  type: NodePort
  selector:
    app: nginx
  ports:
    - name: https
      protocol: TCP
      port: 443 
      targetPort: 443
      nodePort: 30443

    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30080
---
# Source: homelab/templates/observability/grafana/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: grafana
spec:
  selector:
    app: grafana
    app.kubernetes.io/name: grafana
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3000
---
# Source: homelab/templates/observability/loki/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki
spec:
  selector:
    app: loki
    app.kubernetes.io/name: loki
  ports:
    - protocol: TCP
      port: 80
      targetPort: 3100
---
# Source: homelab/templates/observability/prometheus/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus
spec:
  selector:
    app: prometheus
    app.kubernetes.io/name: prometheus
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9090
---
# Source: homelab/templates/openldap/app/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: ldap-user-manager
spec: 
  selector:
    app: ldap-user-manager
    app.kubernetes.io/name: ldap-user-manager
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
---
# Source: homelab/templates/openldap/db/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: openldap
spec: 
  selector:
    app: openldap
    app.kubernetes.io/name: openldap
  ports:
    - protocol: TCP
      port: 389 
      targetPort: 389
---
# Source: homelab/templates/prowlarr/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: prowlarr
spec:
  selector:
    app: prowlarr
    app.kubernetes.io/name: prowlarr
  ports:
    - protocol: TCP
      port: 80
      targetPort: 9696
---
# Source: homelab/templates/qbittorrent/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: qbittorrent
spec:
  selector:
    app: qbittorrent
    app.kubernetes.io/name: qbittorrent
  ports:
    - protocol: TCP
      name: qbittorrent
      port: 80
      targetPort: 8080
---
# Source: homelab/templates/radarr/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: radarr
spec:
  selector:
    app: radarr
    app.kubernetes.io/name: radarr
  ports:
    - protocol: TCP
      port: 80
      targetPort: 7878
---
# Source: homelab/templates/sonarr/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: sonarr
spec:
  selector:
    app: sonarr
    app.kubernetes.io/name: sonarr
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8989
---
# Source: homelab/templates/observability/promtail/daemon.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  annotations:
    configmap.reloader.stakater.com/reload: "promtail-configs"
  name: promtail
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      annotations:
      labels:
        app: promtail
        app.kubernetes.io/name: promtail
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

        - name: host-docker-containers
          hostPath:
            path: /var/lib/docker/containers

        - name: host-log
          hostPath:
            path: /var/log

        - name: host-sock
          hostPath:
            path: /var/run/docker.sock

        - name: promtail-configs
          configMap:
            name: promtail-configs
            items:
              - key: promtail.yaml
                path: promtail.yaml

      containers:
        - name: promtail
          image: grafana/promtail:main-66b36cb
          args:
            - "-config.file=/etc/promtail/promtail.yaml"

          volumeMounts:
            - name: host-log
              mountPath: /var/log

            - name: host-docker-containers
              mountPath: /var/lib/docker/containers

            - name: host-sock
              mountPath: /var/run/docker.sock

            - name: promtail-configs
              mountPath: /etc/promtail/promtail.yaml
              subPath: promtail.yaml
              readOnly: false
---
# Source: homelab/charts/reloader/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    meta.helm.sh/release-namespace: "default"
    meta.helm.sh/release-name: "bingus"
  labels:
    app: bingus-reloader
    chart: "reloader-1.0.50"
    release: "bingus"
    heritage: "Helm"
    app.kubernetes.io/managed-by: "Helm"
    group: com.stakater.platform
    provider: stakater
    version: v1.0.50
  name: bingus-reloader
  namespace: default
spec:
  replicas: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: bingus-reloader
      release: "bingus"
  template:
    metadata:
      labels:
        app: bingus-reloader
        chart: "reloader-1.0.50"
        release: "bingus"
        heritage: "Helm"
        app.kubernetes.io/managed-by: "Helm"
        group: com.stakater.platform
        provider: stakater
        version: v1.0.50
    spec:
      containers:
      - image: "ghcr.io/stakater/reloader:v1.0.50"
        imagePullPolicy: IfNotPresent
        name: bingus-reloader

        ports:
        - name: http
          containerPort: 9090
        livenessProbe:
          httpGet:
            path: /live
            port: http
          timeoutSeconds: 5
          failureThreshold: 5
          periodSeconds: 10
          successThreshold: 1
          initialDelaySeconds: 10
        readinessProbe:
          httpGet:
            path: /metrics
            port: http
          timeoutSeconds: 5
          failureThreshold: 5
          periodSeconds: 10
          successThreshold: 1
          initialDelaySeconds: 10

        securityContext:
          {}
      securityContext: 
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: bingus-reloader
---
# Source: homelab/templates/authelia/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    configmap.reloader.stakater.com/reload: "authelia-configs"
    secret.reloader.stakater.com/reload: "openldap.binddn.password,authelia.session.secret,authelia.encryption.key"
  name: authelia
spec:
  selector:
    matchLabels:
      app: authelia
  replicas: 1
  template:
    metadata:
      labels:
        app: authelia
        app.kubernetes.io/name: authelia
    spec:
      volumes:
        - name: authelia-configs
          configMap:
            name: authelia-configs
            items:
              - key: configuration.yaml
                path: configuration.yaml

      containers:
        - name: authelia
          image: authelia/authelia:4.37.5
          ports:
            - containerPort: 80

          env:
            - name: AUTHELIA_AUTHENTICATION_BACKEND_LDAP_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: openldap.binddn.password
                  key: value

            - name: AUTHELIA_SESSION_SECRET
              valueFrom:
                secretKeyRef:
                  name: authelia.session.secret
                  key: value

            - name: AUTHELIA_STORAGE_ENCRYPTION_KEY
              valueFrom:
                secretKeyRef:
                  name: authelia.encryption.key
                  key: value

          volumeMounts:
            - name: authelia-configs
              mountPath: /config/configuration.yml # expects path at .yml!
              subPath: configuration.yaml
              readOnly: false

      initContainers:
        - name: openldap-389-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z openldap.default.svc.cluster.local 389; do echo waiting for openldap; sleep 3; done;']
---
# Source: homelab/templates/autobrr/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: autobrr
spec:
  selector:
    matchLabels:
      app: autobrr
  replicas: 1
  template:
    metadata:
      labels:
        app: autobrr
        app.kubernetes.io/name: autobrr
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: autobrr
          image: ghcr.io/autobrr/autobrr:latest
          ports:
            - containerPort: 7474

          env:
            - name: AUTOBRR__HOST
              value: "0.0.0.0"

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/autobrr
---
# Source: homelab/templates/calibre/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: calibre
spec:
  selector:
    matchLabels:
      app: calibre
  replicas: 1
  template:
    metadata:
      labels:
        app: calibre
        app.kubernetes.io/name: calibre
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: calibre
          image: linuxserver/calibre-web:0.6.21
          ports:
            - containerPort: 8083

          env:
            - name: DOCKER_MODS
              value: linuxserver/mods:universal-calibre

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/calibre

            - name: data
              mountPath: /books
              subPath: shared/books
---
# Source: homelab/templates/gitea/app/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    secret.reloader.stakater.com/reload: "gitea.db.password"
  name: gitea
spec:
  selector:
    matchLabels:
      app: gitea
  replicas: 1
  template:
    metadata:
      labels:
        app: gitea
        app.kubernetes.io/name: gitea
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: giteadb
          image: postgres
          ports:
            - containerPort: 5432

          env:
            - name: POSTGRES_USER
              value: postgres

            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gitea.db.password
                  key: value           

          volumeMounts:
            - name: data
              mountPath: /var/lib/postgresql/data
              subPath: application/gitea/db

        - name: gitea
          image: gitea/gitea:1.20.5
          ports:
            - containerPort: 3000
            - containerPort: 2222

          env:
            - name: GITEA__database__DB_TYPE
              value: postgres

            - name: GITEA__database__HOST
              value: 0.0.0.0:5432

            - name: GITEA__database__NAME
              value: postgres

            - name: GITEA__database__USER
              value: postgres

            - name: GITEA_database__PASSWD
              valueFrom:
                secretKeyRef:
                  name: gitea.db.password
                  key: value

            - name: GITEA__actions__ENABLED
              value: "true"

            - name: GITEA__metrics__ENABLED
              value: "true"

            - name: GITEA__server__ROOT_URL
              value: "http://gitea"

          volumeMounts:
            - name: data
              mountPath: /data/gitea
              subPath: application/gitea/data

            - name: data
              mountPath: /data/git/repositories
              subPath: application/gitea/repos

            - name: data
              mountPath: /data/git/lfs
              subPath: application/gitea/lfs
---
# Source: homelab/templates/gitea/runner/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    secret.reloader.stakater.com/reload: gitea.runner.token
  name: gitea-runner
spec:
  selector:
    matchLabels:
      app: gitea-runner
  replicas: 1
  template:
    metadata:
      labels:
        app: gitea-runner
        app.kubernetes.io/name: gitea-runner
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

        - name: gitea-container-images
          hostPath:
            path: /gitea-container-images

        - name: docker-certs
          emptyDir: {}

      securityContext:
        fsGroup: 1000

      containers:
        - name: gitea-runner-daemon
          image: docker:23.0.6-dind
          env:
          - name: DOCKER_TLS_CERTDIR
            value: /certs

          securityContext:
            privileged: true

          volumeMounts:
            - name: docker-certs
              mountPath: /certs

            - name: gitea-container-images
              mountPath: /var/lib/docker

        - name: gitea-runner
          image: gitea/act_runner

          securityContext:
            privileged: true

          env:
            - name: DOCKER_HOST
              value: tcp://localhost:2376

            - name: DOCKER_CERT_PATH
              value: /certs/client

            - name: DOCKER_TLS_VERIFY
              value: "1"

            - name: GITEA_INSTANCE_URL
              value: "http://gitea"

            - name: GITEA_RUNNER_REGISTRATION_TOKEN
              valueFrom:
                secretKeyRef:
                  name: gitea.runner.token
                  key: value

          volumeMounts:
            - name: docker-certs
              mountPath: /certs

            - name: data
              mountPath: /data
              subPath: application/gitea/runner

        

      initContainers: 
        - name: gitea-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z gitea.default.svc.cluster.local 80; do echo waiting for gitea; sleep 3; done;']
---
# Source: homelab/templates/jellyfin/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jellyfin
spec:
  selector:
    matchLabels:
      app: jellyfin
  replicas: 1
  template:
    metadata:
      labels:
        app: jellyfin
        app.kubernetes.io/name: jellyfin
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: jellyfin
          image: linuxserver/jellyfin
          ports:
            - containerPort: 8096

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/jellyfin

            - name: data
              mountPath: /data/movies
              subPath: shared/movies

            - name: data
              mountPath: /data/tvshows
              subPath: shared/tv
---
# Source: homelab/templates/miniflux/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    secret.reloader.stakater.com/reload: "miniflux.db.password"
  name: miniflux
spec:
  selector:
    matchLabels:
      app: miniflux
  replicas: 1
  template:
    metadata:
      labels:
        app: miniflux
        app.kubernetes.io/name: miniflux
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: miniflux-db
          image: postgres:16.0
          ports:
            - containerPort: 5432

          env:
            - name: POSTGRES_USER
              value: postgres

            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: miniflux.db.password
                  key: value

          readinessProbe:
            tcpSocket:
              port: 5432
            initialDelaySeconds: 15
            periodSeconds: 10

          volumeMounts:
            - name: data
              mountPath: /var/lib/postgresql/data
              subPath: application/miniflux/db

        - name: miniflux
          image: miniflux/miniflux:2.0.49
          ports:
            - containerPort: 8080

          env:
            - name: METRICS_COLLECTOR
              value: "1"

            - name: RUN_MIGRATIONS
              value: "1"

            - name: CREATE_ADMIN
              value: "1"

            - name: ADMIN_USERNAME
              value: kwkaiser

            - name: ADMIN_PASSWORD
              value: password

            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: miniflux.db.connection.string
                  key: value
---
# Source: homelab/templates/nginx/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    configmap.reloader.stakater.com/reload: "nginx-configs"
    secret.reloader.stakater.com/reload: "nginx.certificate.key,nginx.certificate"
  name: nginx
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 1
  template:
    metadata:
      labels:
        app: nginx
        app.kubernetes.io/name: nginx
    spec: 
      # Load balancer always run on head
      nodeSelector:
        head: "true"

      volumes:
        - name: nginx-certificate-key
          secret:
            secretName: nginx.certificate.key
            items:
              - key: value
                path: value
        - name: nginx-certificate
          secret:
            secretName: nginx.certificate
            items:
              - key: value
                path: value

        - name: nginx-configs
          configMap:
            name: nginx-configs
            items:
              - key: authelia-endpoint.conf
                path: authelia-endpoint.conf
              - key: authelia-location.conf
                path: authelia-location.conf
              - key: authelia-proxy.conf
                path: authelia-proxy.conf
              - key: conf.d_auth.conf
                path: conf.d_auth.conf
              - key: conf.d_books.conf
                path: conf.d_books.conf
              - key: conf.d_default.conf
                path: conf.d_default.conf
              - key: conf.d_git.conf
                path: conf.d_git.conf
              - key: conf.d_ldap-user-manager.conf
                path: conf.d_ldap-user-manager.conf
              - key: conf.d_movies.conf
                path: conf.d_movies.conf
              - key: conf.d_news.conf
                path: conf.d_news.conf
              - key: conf.d_ratio.conf
                path: conf.d_ratio.conf
              - key: conf.d_scurvy.conf
                path: conf.d_scurvy.conf
              - key: conf.d_stats.conf
                path: conf.d_stats.conf
              - key: conf.d_trackers.conf
                path: conf.d_trackers.conf
              - key: conf.d_tv.conf
                path: conf.d_tv.conf
              - key: conf.d_watch.conf
                path: conf.d_watch.conf
              - key: https.conf
                path: https.conf
              - key: nginx.conf
                path: nginx.conf

      containers:
        - name: nginx
          image: nginx:1.25.3
          ports:
            - containerPort: 80
            - containerPort: 443

          volumeMounts:
            - name: nginx-certificate
              mountPath: /etc/nginx/keys/kwkaiser-test.io.crt
              subPath: value
              readOnly: true
            - name: nginx-certificate-key
              mountPath: /etc/nginx/keys/kwkaiser-test.io.key
              subPath: value
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/authelia-endpoint.conf 
              subPath: authelia-endpoint.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/authelia-location.conf 
              subPath: authelia-location.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/authelia-proxy.conf 
              subPath: authelia-proxy.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/auth.conf 
              subPath: conf.d_auth.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/books.conf 
              subPath: conf.d_books.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/default.conf 
              subPath: conf.d_default.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/git.conf 
              subPath: conf.d_git.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/ldap-user-manager.conf 
              subPath: conf.d_ldap-user-manager.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/movies.conf 
              subPath: conf.d_movies.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/news.conf 
              subPath: conf.d_news.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/ratio.conf 
              subPath: conf.d_ratio.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/scurvy.conf 
              subPath: conf.d_scurvy.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/stats.conf 
              subPath: conf.d_stats.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/trackers.conf 
              subPath: conf.d_trackers.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/tv.conf 
              subPath: conf.d_tv.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/conf.d/watch.conf 
              subPath: conf.d_watch.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/https.conf 
              subPath: https.conf
              readOnly: true
            - name: nginx-configs
              mountPath: /etc/nginx/nginx.conf 
              subPath: nginx.conf
              readOnly: true 
      initContainers:
        - name: authelia-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z authelia.default.svc.cluster.local 80; do echo waiting for authelia; sleep 3; done;']
        - name: ldap-user-manager-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z ldap-user-manager.default.svc.cluster.local 80; do echo waiting for ldap-user-manager; sleep 3; done;']
        - name: jellyfin-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z jellyfin.default.svc.cluster.local 80; do echo waiting for jellyfin; sleep 3; done;']
        - name: calibre-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z calibre.default.svc.cluster.local 80; do echo waiting for calibre; sleep 3; done;']
        - name: gitea-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z gitea.default.svc.cluster.local 80; do echo waiting for gitea; sleep 3; done;']
        - name: prometheus-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z prometheus.default.svc.cluster.local 80; do echo waiting for prometheus; sleep 3; done;']
        - name: radarr-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z radarr.default.svc.cluster.local 80; do echo waiting for radarr; sleep 3; done;']
        - name: sonarr-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z sonarr.default.svc.cluster.local 80; do echo waiting for sonarr; sleep 3; done;']
        - name: prowlarr-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z prowlarr.default.svc.cluster.local 80; do echo waiting for prowlarr; sleep 3; done;']
        - name: autobrr-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z autobrr.default.svc.cluster.local 80; do echo waiting for autobrr; sleep 3; done;']
        - name: qbittorrent-80-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z qbittorrent.default.svc.cluster.local 80; do echo waiting for qbittorrent; sleep 3; done;']
---
# Source: homelab/templates/observability/grafana/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    configmap.reloader.stakater.com/reload: "grafana-configs"
  name: grafana
spec:
  selector:
    matchLabels:
      app: grafana
  replicas: 1
  template:
    metadata:
      labels:
        app: grafana
        app.kubernetes.io/name: grafana
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

        - name: grafana-configs
          configMap:
            name: grafana-configs
            items:
              - key: config.ini
                path: config.ini

      containers:
        - name: grafana
          image: grafana/grafana:10.2.0
          ports:
            - containerPort: 3000
          args:
            - "--config=/config.ini"

          volumeMounts:
            - name: data
              mountPath: /var/lib/grafana
              subPath: application/grafana

            - name: grafana-configs
              mountPath: config.ini 
              subPath: config.ini
              readOnly: false
---
# Source: homelab/templates/observability/loki/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    configmap.reloader.stakater.com/reload: "loki-configs"
  name: loki
spec:
  selector:
    matchLabels:
      app: loki
  replicas: 1
  template:
    metadata:
      labels:
        app: loki
        app.kubernetes.io/name: loki
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

        - name: loki-configs
          configMap:
            name: loki-configs
            items:
              - key: configuration.yaml
                path: configuration.yaml

      containers:
        - name: loki
          image: grafana/loki:main-66b36cb
          ports:
            - containerPort: 3100

          volumeMounts:
            - name: data
              mountPath: /loki
              subPath: application/loki

            # - name: loki-configs
            #   mountPath: /etc/loki/local-config.yaml
            #   subPath: configuration.yaml
            #   readOnly: false
---
# Source: homelab/templates/observability/prometheus/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    configmap.reloader.stakater.com/reload: "prometheus-configs"
  name: prometheus
spec:
  selector:
    matchLabels:
      app: prometheus
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        app.kubernetes.io/name: prometheus
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

        - name: prometheus-configs
          configMap:
            name: prometheus-configs
            items:
              - key: configuration.yaml
                path: configuration.yaml

      containers:
        - name: prometheus
          image: bitnami/prometheus:2.47.2
          ports:
            - containerPort: 9090 

          volumeMounts:
            - name: data
              mountPath: /opt/bitnami/prometheus/data
              subPath: application/prometheus

            - name: prometheus-configs
              mountPath: /opt/bitnami/prometheus/conf/prometheus.yml
              subPath: configuration.yaml
              readOnly: false
---
# Source: homelab/templates/openldap/app/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ldap-user-manager
  annotations:
    secret.reloader.stakater.com/reload: "openldap.binddn.password"
spec:
  selector:
    matchLabels:
      app: ldap-user-manager
  replicas: 1
  template:
    metadata:
      labels:
        app: ldap-user-manager
        app.kubernetes.io/name: ldap-user-manager
    spec:
      containers:
        - name: ldap-user-manager
          image: wheelybird/ldap-user-manager:v1.11
          ports:
            - containerPort: 80
          env:
            - name: NO_HTTPS
              value: "true"

            - name: LDAP_URI
              value: ldap://openldap

            - name: LDAP_REQUIRE_STARTTLS
              value: "false"

            - name: LDAP_BASE_DN
              value: "dc=kwkaiser-test,dc=io"

            - name: LDAP_ADMIN_BIND_DN
              value: "cn=admin,dc=kwkaiser-test,dc=io"

            - name: LDAP_ADMINS_GROUP
              value: admins

            - name: LDAP_ADMIN_BIND_PWD
              valueFrom:
                secretKeyRef:
                  name: openldap.binddn.password
                  key: value

            - name: LDAP_IGNORE_CERT_ERRORS
              value: "true"

            - name: LDAP_VERBOSE_CONNECTION_LOGS
              value: "true"

            - name: LDAP_DEBUG
              value: "true"

      initContainers:
        - name: openldap-389-init
          image: busybox
          command: ['sh', '-c', 'until nc -w 2 -z openldap.default.svc.cluster.local 389; do echo waiting for openldap; sleep 3; done;']
---
# Source: homelab/templates/openldap/db/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openldap
  annotations:
    secret.reloader.stakater.com/reload: "openldap.binddn.password"
spec: 
  selector:
    matchLabels:
      app: openldap
  replicas: 1
  template:
    metadata:
      labels: 
        app: openldap
        app.kubernetes.io/name: openldap
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: openldap
          image: osixia/openldap:1.5.0
          ports:
            - containerPort: 636
            - containerPort: 389

          args: ["--loglevel", "debug", "--copy-service"]

          env:
            - name: LDAP_ORGANISATION
              value: kwkaiser-test.io

            - name: LDAP_DOMAIN
              value: kwkaiser-test.io

            - name: LDAP_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: openldap.binddn.password
                  key: value
            
            - name: LDAP_REQUIRE_STARTTLS
              value: "false"

            - name: HOSTNAME
              value: openldap

            - name: LDAP_TLS
              value: "false"

            - name: LDAP_RFC2307BIS_SCHEMA
              value: "true"

          volumeMounts:
            - name: data
              mountPath: /var/lib/ldap
              subPath: application/openldap/data

            - name: data 
              mountPath: /etc/ldap/slapd.d
              subPath: application/openldap/slapd
---
# Source: homelab/templates/prowlarr/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prowlarr
spec:
  selector:
    matchLabels:
      app: prowlarr
  replicas: 1
  template:
    metadata:
      labels:
        app: prowlarr
        app.kubernetes.io/name: prowlarr
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: prowlarr
          image: linuxserver/prowlarr:1.9.4
          ports:
            - containerPort: 9696

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/prowlarr
---
# Source: homelab/templates/qbittorrent/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: qbittorrent
spec:
  selector:
    matchLabels:
      app: qbittorrent
  replicas: 1
  template:
    metadata:
      labels:
        app: qbittorrent
        app.kubernetes.io/name: qbittorrent
    spec:
      securityContext:
        sysctls:
          - name: net.ipv4.conf.all.src_valid_mark
            value: "1"
          - name: net.ipv6.conf.all.disable_ipv6
            value: "0"

      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs
        - name: wireguard-key
          secret:
            secretName: wireguard.key
            items:
              - key: value
                path: value

      containers:
        - name: wireguard
          image: linuxserver/wireguard:1.0.20210914
          ports:
            - containerPort: 51820

          volumeMounts:
            - name: wireguard-key
              mountPath: /config/wg0.conf
              subPath: value

          # Hooks to guarantee we connected to target IP & stayed connected.
          lifecycle:
            postStart:
              exec:
                command:
                  - sh
                  - -c
                  - sleep 30 && until curl --connect-timeout 10 ifconfig.me | grep -i ""; do echo "Waiting for ifconfig response"; sleep 10; done;
          livenessProbe:
            exec:
              command:
                - bash
                - -c
                - exit "$(curl ifconfig.me --connect-timeout 30 | grep -i '')"
            initialDelaySeconds: 120
            periodSeconds: 120
            timeoutSeconds: 30

          securityContext:
            privileged: true
            capabilities:
              add:
                - NET_ADMIN
                - NET_BIND
                - NET_RAW
                - SYS_MODULE

        - name: qbittorrent
          image: linuxserver/qbittorrent:4.6.0
          ports:
            - containerPort: 8080
            - containerPort: 6881

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/qbittorrent

            - name: data
              mountPath: /shared/torrents
              subPath: shared/torrents
---
# Source: homelab/templates/radarr/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: radarr
spec:
  selector:
    matchLabels:
      app: radarr
  replicas: 1
  template:
    metadata:
      labels:
        app: radarr
        app.kubernetes.io/name: radarr
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: radarr
          image: linuxserver/radarr:5.0.3
          ports:
            - containerPort: 7878

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/radarr

            - name: data
              mountPath: /shared/torrents
              subPath: shared/torrents

            - name: data
              mountPath: /shared/movies
              subPath: shared/movies
---
# Source: homelab/templates/sonarr/depl.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sonarr
spec:
  selector:
    matchLabels:
      app: sonarr
  replicas: 1
  template:
    metadata:
      labels:
        app: sonarr
        app.kubernetes.io/name: sonarr
    spec:
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: bulk-nfs

      containers:
        - name: sonarr
          image: linuxserver/sonarr:3.0.10
          ports:
            - containerPort: 8989

          volumeMounts:
            - name: data
              mountPath: /config
              subPath: application/sonarr

            - name: data
              mountPath: /shared/torrents
              subPath: shared/torrents

            - name: data
              mountPath: /shared/movies
              subPath: shared/movies
---
# Source: homelab/templates/gitea/renovate/cron.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  annotations:
    secret.reloader.stakater.com/reload: "gitea.renovate.token"
  name: renovate
spec:
  schedule: "0 0 * * *"
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: Never
          volumes:
            - name: data
              persistentVolumeClaim:
                claimName: bulk-nfs

            - name: renovate-configs
              configMap:
                name: renovate-configs
                items:
                  - key: config.json
                    path: config.json

          containers:
            - name: gitea-renovate
              image: renovate/renovate:37.33.5

              env:
                - name: LOG_LEVEL
                  value: debu0g

                - name: RENOVATE_CONFIG_FILE
                  value: /usr/src/app/config.json

                - name: RENOVATE_AUTODISCOVER
                  value: "true"

                - name: RENOVATE_TOKEN
                  valueFrom:
                    secretKeyRef:
                      name: gitea.renovate.token
                      key: value

              volumeMounts:
                - name: renovate-configs
                  mountPath: /usr/src/app/config.json
                  subPath: config.json
                  readOnly: false
---
# Source: homelab/templates/helpers.tpl
# Waits for another pod in the cluster to be up & listening on a port

